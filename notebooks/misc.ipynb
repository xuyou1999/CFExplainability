{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import local packages, e.g., dice, spotlight, and contant variables setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "for p in ['../spotlight_ext', '../dice_ext']:\n",
    "    module_path = os.path.abspath(os.path.join(p))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = '../models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage example for spotlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "# from spotlight.evaluation import mrr_score\n",
    "# from spotlight.factorization.implicit import ImplicitFactorizationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = get_movielens_dataset(variant='100K')\n",
    "\n",
    "# train, test = random_train_test_split(dataset)\n",
    "\n",
    "# model = ImplicitFactorizationModel(n_iter=3, loss='bpr')\n",
    "# model.fit(train)\n",
    "\n",
    "# mrr = mrr_score(model, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sequential models** (candidate for our problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spotlight.cross_validation import user_based_train_test_split\n",
    "# from spotlight.datasets.synthetic import generate_sequential\n",
    "\n",
    "\n",
    "# dataset = generate_sequential(num_users=100,\n",
    "#                               num_items=1000,\n",
    "#                               num_interactions=10000,\n",
    "#                               concentration_parameter=0.01,\n",
    "#                               order=3)\n",
    "\n",
    "# train, test = user_based_train_test_split(dataset)\n",
    "\n",
    "dataset = get_movielens_dataset(variant='1M')\n",
    "train, test = random_train_test_split(dataset, random_state=np.random.RandomState(2020))\n",
    "\n",
    "max_sequence_length = 20\n",
    "train = train.to_sequence(max_sequence_length=max_sequence_length)\n",
    "test = test.to_sequence(max_sequence_length=max_sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.evaluation import sequence_mrr_score\n",
    "\n",
    "model = ImplicitSequenceModel(\n",
    "    batch_size=256,\n",
    "    embedding_dim=32,\n",
    "    l2=0.0,\n",
    "    learning_rate=0.05,\n",
    "    n_iter=11,\n",
    "    representation='lstm',\n",
    "    loss='adaptive_hinge',\n",
    "#     use_cuda=torch.cuda.is_available(),\n",
    "    random_state=np.random.RandomState(2020)\n",
    ")\n",
    "model.fit(train)\n",
    "\n",
    "mrr = sequence_mrr_score(model, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofile = 'entire_model_1m_20interactions.pt'\n",
    "torch.save(model, os.path.join(models_path, ofile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## or load a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofile = 'entire_model_1m.pt'\n",
    "\n",
    "model = torch.load(os.path.join(models_path, ofile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_interacted = test.sequences[test.user_ids==2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item to predict: 134\n"
     ]
    }
   ],
   "source": [
    "predictions = -model.predict(items_interacted[:-1])\n",
    "print(f'Item to predict: {items_interacted[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_item_pos = st.rankdata(predictions, method='ordinal')[items_interacted[-1]]\n",
    "next_item_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, -0.9794686)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(enumerate(predictions), key=lambda x: x[1])[int(next_item_pos) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = dict(\n",
    "#     n_iter=st.randint(10, 20),\n",
    "#     representation=['cnn', 'lstm', 'mixture'],\n",
    "#     loss=['adaptive_hinge', 'hinge', 'bpr'],\n",
    "#     embedding_dim=[32, 64, 128, 256],\n",
    "#     batch_size=[32, 64, 128, 256],\n",
    "#     learning_rate=st.expon(loc=0.0001, scale=0.1),\n",
    "#     l2=st.expon(loc=0.0, scale=0.1)\n",
    "# )\n",
    "# score = make_scorer(sequence_mrr_score)\n",
    "                    \n",
    "# grid = RandomizedSearchCV(\n",
    "#     estimator=ImplicitSequenceModel(), param_distributions=param_grid, n_jobs=4, cv=3,\n",
    "#     scoring=score, verbose=1, n_iter=100\n",
    "# )\n",
    "# grid_result = grid.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal convolutions for sequence-based recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'embedding_dim': 128,\n",
    "    'kernel_width': 5,\n",
    "    'dilation': [1, 2, 4],\n",
    "    'num_layers': 5,\n",
    "    'nonlinearity': 'relu',\n",
    "    'residual': True,\n",
    "    'loss': 'adaptive_hinge',\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 0.01,\n",
    "    'l2': 0,\n",
    "    'n_iter': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.sequence.representations import CNNNet\n",
    "from spotlight.evaluation import sequence_mrr_score\n",
    "\n",
    "\n",
    "net = CNNNet(train.num_items,\n",
    "             embedding_dim=hyperparameters['embedding_dim'],\n",
    "             kernel_width=hyperparameters['kernel_width'],\n",
    "             dilation=hyperparameters['dilation'],\n",
    "             num_layers=hyperparameters['num_layers'],\n",
    "             nonlinearity=hyperparameters['nonlinearity'],\n",
    "             residual_connections=hyperparameters['residual'])\n",
    "\n",
    "model = ImplicitSequenceModel(loss=hyperparameters['loss'],\n",
    "                              representation=net,\n",
    "                              batch_size=hyperparameters['batch_size'],\n",
    "                              learning_rate=hyperparameters['learning_rate'],\n",
    "                              l2=hyperparameters['l2'],\n",
    "                              n_iter=hyperparameters['n_iter'],\n",
    "                              use_cuda=torch.cuda.is_available(),\n",
    "#                               random_state=random_state\n",
    "                             )\n",
    "\n",
    "model.fit(train)\n",
    "\n",
    "test_mrr = sequence_mrr_score(model, test)\n",
    "# val_mrr = sequence_mrr_score(model, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MRR [0.01612903 0.0060241  0.00290698 0.00218818 0.05263158 0.00220751\n",
      " 0.01052632 0.0052356  0.03333333 0.00108696 0.05       0.33333333\n",
      " 0.00411523 0.00108696 0.00116009 0.01754386 0.00115875 0.00174216\n",
      " 1.         0.00273224 0.00103199 0.01149425 0.01470588 0.00150376\n",
      " 0.00115741 0.00134771 0.00526316 0.00189036 0.00181488 0.00409836\n",
      " 0.00537634 0.00101833 0.01075269 0.00168067 1.         0.00232019\n",
      " 0.00315457 0.01020408 0.00111235 0.00290698 0.125      0.00584795\n",
      " 0.01149425 0.00970874 0.0013624  0.00161812 0.00175439 0.00308642\n",
      " 0.00275482 1.         0.00137931 0.00423729 0.16666667 0.00187266\n",
      " 0.00138122 0.00154799 0.00485437 0.00121951 0.00127877 0.125\n",
      " 0.00117647 0.00507614 0.00564972 1.         0.01960784 0.00169205\n",
      " 0.00172414 0.00198807 0.01282051 0.0010989  0.00555556 0.00116686\n",
      " 0.00247525 0.00689655 0.01492537 0.0037037  0.01315789 0.001321\n",
      " 0.00143472 0.001287   0.00662252 0.00168919 0.00280899 0.00298507\n",
      " 0.004      0.03333333 0.00204499 0.0013245  0.00181818 0.00111982\n",
      " 0.01470588 0.00813008 0.00106724 0.00294118 0.02439024 0.00229358\n",
      " 0.00122549 0.00116144 0.00104384 0.00151976 0.01923077 0.00168634\n",
      " 0.00122699 0.00358423 0.05       0.00327869 0.00159236 0.00160514\n",
      " 0.00108342 0.0020202  0.01234568 0.00487805 0.03846154 0.00584795\n",
      " 0.00106045 0.00245098 0.00230415 0.00645161 0.00296736 0.00108578\n",
      " 0.00348432 0.0011919  0.00595238 0.5        0.05882353 0.00198807\n",
      " 0.00383142 0.04       0.02       0.00290698 0.0022779  0.04166667\n",
      " 0.00294118 0.01315789 0.01123596 0.00357143 0.00296736 0.00139665\n",
      " 0.00163399 0.00139276 0.02222222 0.00107875 0.00344828 0.00176367\n",
      " 0.00854701 0.00310559 0.00146628 0.00222222 0.0014556  0.00196078\n",
      " 0.00309598 0.00460829 0.00341297 0.0013089  0.00191205 0.00675676\n",
      " 0.00234192 0.01010101 0.00201207 0.00234742 0.00144928 0.00371747\n",
      " 0.00392157 0.00657895 0.0022779  0.00332226 0.0014881  0.00324675\n",
      " 0.0044843  0.00140056 0.00121507 0.00411523 0.00438596 0.0015083\n",
      " 0.00233645 0.003663   0.00149701 0.00138504 0.01075269 0.00132275\n",
      " 0.005      0.03703704 0.00105597 0.003003   0.00132979 0.00211864\n",
      " 0.00531915 0.0041841  0.00361011 0.00114679 0.00179856 0.00423729\n",
      " 0.00124069 0.00132626 0.00558659 0.00578035 0.00209205 0.00132802\n",
      " 0.09090909 0.00137174 0.0010929  0.00406504 0.00218341 0.03571429\n",
      " 0.00100908 0.00146628 0.00138696 0.0034965  0.00225734 0.01234568\n",
      " 0.00105932 0.003663   0.00173913 0.00215054 0.00209205 0.00201613\n",
      " 0.00478469 0.0014556  0.00170358 0.00114025 0.00306748 0.00104712\n",
      " 0.00299401 0.00235849 0.00294118 0.0012837 ]\n"
     ]
    }
   ],
   "source": [
    "print(f'Test MRR {test_mrr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage example for DiCE with torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dice_ml\n",
    "from dice_ml.utils import helpers # helper functions\n",
    "\n",
    "backend = 'PYT'\n",
    "# Dataset for training an ML model\n",
    "d = dice_ml.Data(dataframe=helpers.load_adult_income_dataset(),\n",
    "                 continuous_features=['age', 'hours_per_week'],\n",
    "                 outcome_name='income')\n",
    "# Pre-trained ML model\n",
    "m = dice_ml.Model(model_path=dice_ml.utils.helpers.get_adult_income_modelpath(backend=backend), backend=backend)\n",
    "# DiCE explanation instance\n",
    "exp = dice_ml.Dice(d, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_instance = {\n",
    "    'age':22,\n",
    "    'workclass':'Private',\n",
    "    'education':'HS-grad',\n",
    "    'marital_status':'Single',\n",
    "    'occupation':'Service',\n",
    "    'race': 'White',\n",
    "    'gender':'Female',\n",
    "    'hours_per_week': 45\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diverse Counterfactuals found! total time taken: 00 min 03 sec\n",
      "Query instance (original outcome : 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Single</td>\n",
       "      <td>Service</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age workclass education marital_status occupation   race  gender  \\\n",
       "0  22.0   Private   HS-grad         Single    Service  White  Female   \n",
       "\n",
       "   hours_per_week    income  \n",
       "0            45.0  0.000042  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diverse Counterfactual set (new outcome : 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>Married</td>\n",
       "      <td>Service</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>Married</td>\n",
       "      <td>Service</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Married</td>\n",
       "      <td>Service</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age      workclass    education marital_status    occupation   race  \\\n",
       "0  57.0        Private    Doctorate        Married  White-Collar  White   \n",
       "1  33.0        Private  Prof-school        Married       Service  White   \n",
       "2  22.0  Self-Employed  Prof-school        Married       Service  White   \n",
       "3  49.0        Private      Masters        Married       Service  White   \n",
       "\n",
       "   gender  hours_per_week  income  \n",
       "0  Female            45.0   0.993  \n",
       "1    Male            39.0   0.964  \n",
       "2  Female            45.0   0.748  \n",
       "3  Female            62.0   0.957  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate counterfactual examples\n",
    "dice_exp = exp.generate_counterfactuals(query_instance, total_CFs=4, desired_class=\"opposite\")\n",
    "# Visualize counterfactual explanation\n",
    "dice_exp.visualize_as_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute-force example on Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model\n",
    "ofile = 'entire_model_1m.pt'\n",
    "model = torch.load(os.path.join(models_path, ofile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize input parameters\n",
    "k = 10\n",
    "no_interactions = 5\n",
    "user_id = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectedInteractions:\n",
    "    def __init__(self, p=-1, i=None):\n",
    "        pos = p\n",
    "        interactions = i\n",
    "        \n",
    "    def __str__(self): \n",
    "        items_order = [(n[0], n[1].detach().numpy().flatten()[0]) if isinstance(n[1], torch.Tensor) else (n[0], n[1]) for n in self.items_order]\n",
    "            \n",
    "        return (f'Found in iter {self.counter_found_best} with score/in pos {self.score} with interactions {self.interactions}\\n'\n",
    "                f'10-best proposed items {items_order}')\n",
    "    \n",
    "    score = 0\n",
    "    pos = -1\n",
    "    interactions = []\n",
    "    items_order = []\n",
    "    counter_found_best = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the following interactions [227 501 492 454 463] for user 8 the next most 10 possible itemsto interact with are [510, 438, 284, 40, 281, 60, 539, 313, 325, 439]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose one of the above next interacted items that should become less candidate:  325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pos of selected item 325 is 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items_interacted = test.sequences[test.user_ids==user_id][0]\n",
    "predictions = -model.predict(items_interacted[:no_interactions])\n",
    "\n",
    "print(f'Given the following interactions {items_interacted[:no_interactions]} for user {user_id} the next most {k} possible items'\n",
    "      f'to interact with are {list(predictions.argsort()[:k])}')\n",
    "cand = input('Choose one of the above next interacted items that should become less candidate: ')\n",
    "try:\n",
    "    cand = int(cand)\n",
    "except ValueError:\n",
    "    print(\"That's not an int!\")\n",
    "\n",
    "print(f'Current pos of selected item {cand} is {st.rankdata(predictions, method=\"ordinal\")[cand]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found in iter 2 with score/in pos 180 with interactions (501,)\n",
      "10-best proposed items [(568, 0.0023526023), (306, 0.002310076), (39, 0.002220974), (892, 0.0020520852), (326, 0.0019568491), (1119, 0.0018849755), (466, 0.0017736341), (86, 0.0017688118), (147, 0.0015101795), (918, 0.0014980054)] \n",
      "Total iterations: 326\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "counter = 1\n",
    "best_inter = SelectedInteractions()\n",
    "\n",
    "for l in range(1, no_interactions + 1):\n",
    "    perm = permutations(items_interacted[:no_interactions], l)    \n",
    "\n",
    "    for i in list(perm):        \n",
    "        preds = model.predict(i) \n",
    "        tensor = torch.from_numpy(preds).float()\n",
    "        preds = F.softmax(tensor, dim=0)        \n",
    "        item_pos = st.rankdata(-preds, method='ordinal')[cand]\n",
    "        if item_pos > best_inter.score:\n",
    "            best_inter.score = item_pos\n",
    "            best_inter.interactions = i\n",
    "            best_inter.items_order = sorted(enumerate(preds), key=lambda x: x[1], reverse=True)[:k]\n",
    "            best_inter.counter_found_best = counter\n",
    "\n",
    "        counter += 1\n",
    "    \n",
    "print(best_inter, f'\\nTotal iterations: {counter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status: optimal\n",
      "optimal value 1.0\n",
      "optimal var 1.0 1.570086213240983e-22\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "\n",
    "# Create two scalar optimization variables.\n",
    "x = cp.Variable()\n",
    "y = cp.Variable()\n",
    "\n",
    "# Create two constraints.\n",
    "constraints = [x + y == 1,\n",
    "               x - y >= 1]\n",
    "\n",
    "# Form objective.\n",
    "obj = cp.Minimize((x - y)**2)\n",
    "\n",
    "# Form and solve problem.\n",
    "prob = cp.Problem(obj, constraints)\n",
    "prob.solve()  # Returns the optimal value.\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)\n",
    "print(\"optimal var\", x.value, y.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value 4.141338603672535\n",
      "Optimal var\n",
      "[-4.95922264e-21  6.07571976e-21  1.34643668e-01  1.24976681e-01\n",
      " -4.57130806e-21]\n"
     ]
    }
   ],
   "source": [
    "# Solves a bounded least-squares problem.\n",
    "\n",
    "import cvxpy as cp\n",
    "import numpy\n",
    "\n",
    "# Problem data.\n",
    "m = 10\n",
    "n = 5\n",
    "numpy.random.seed(1)\n",
    "A = numpy.random.randn(m, n)\n",
    "b = numpy.random.randn(m)\n",
    "\n",
    "# Construct the problem.\n",
    "x = cp.Variable(n)\n",
    "objective = cp.Minimize(cp.sum_squares(A @ x - b))\n",
    "constraints = [0 <= x, x <= 1]\n",
    "prob = cp.Problem(objective, constraints)\n",
    "\n",
    "print(\"Optimal value\", prob.solve())\n",
    "print(\"Optimal var\")\n",
    "print(x.value) # A numpy ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['item_id', 'rating', 'timestamp', 'user_id']>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "filename = \"~/spotlight_data/movielens/v0.2.0/movielens_movielens_100K.hdf5\"\n",
    "\n",
    "with h5py.File(os.path.expanduser(filename), \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    a_group_key = list(f.keys())[0]\n",
    "\n",
    "    # Get the data\n",
    "    data = list(f[a_group_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"jupyter nbconvert misc.ipynb --to slides\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook misc.ipynb to pdf\n",
      "[NbConvertApp] Writing 63994 bytes to notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 64232 bytes to misc.pdf\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert misc.ipynb --to pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vkaff/gits/CFExplainability/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive.ics.uci.edu\t    matrix_factorization_for_rec_expl.ipynb\n",
      "brute_force_rec_expl.ipynb  misc.ipynb\n",
      "budget_strategies.ipynb     misc.pdf\n",
      "cvxpy_usage_rec_expl.ipynb  pooling_repr_for_rec_expl.ipynb\n",
      "Dice_test.ipynb\t\t    README.md\n",
      "fair_rec\t\t    score_preds.ipynb\n",
      "helpers.ipynb\t\t    torch_rec\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CFExplainability",
   "language": "python",
   "name": "cfexplainability"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
