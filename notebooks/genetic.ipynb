{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats as st\n",
    "import itertools\n",
    "import operator\n",
    "\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "from tqdm import tqdm\n",
    "\n",
    "random_state = np.random.RandomState(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb')\n",
    "%run $helpers_file\n",
    "\n",
    "# Load spotlight module\n",
    "for p in ['../spotlight_ext']:\n",
    "    module_path = os.path.abspath(os.path.join(base_dir, p))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = load_model(model_type='entire')\n",
    "pooling_model = load_model('pooling')\n",
    "\n",
    "pretrained_models = {\n",
    "    'lstm': lstm_model,\n",
    "    'pooling': pooling_model,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "\n",
    "# get dataset\n",
    "dataset = get_movielens_dataset(variant='1M')\n",
    "train, test = random_train_test_split(dataset, random_state=random_state)\n",
    "\n",
    "max_sequence_length = 20\n",
    "train = train.to_sequence(max_sequence_length=max_sequence_length)\n",
    "test = test.to_sequence(max_sequence_length=max_sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target item is 149 in this test case, top k is 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 59, 114, 124, 125, 177, 186, 190, 191, 196, 197, 200], dtype=int32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_interaction = test.sequences[test.user_ids == 3][0].copy()\n",
    "test_interaction = test_interaction[test_interaction != 0]\n",
    "test_interaction.sort()\n",
    "test_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_test_interaction = len(test_interaction)\n",
    "len_test_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position_item(model, test_interaction, position=1):\n",
    "    prediction = model.predict(test_interaction)\n",
    "    prediction[test_interaction] = -StaticVars.FLOAT_MAX\n",
    "    rk_data = st.rankdata(-prediction, method='ordinal')\n",
    "    index = np.where(rk_data == position)\n",
    "    return index[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_position_item(pooling_model, test_interaction, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random CF candidate selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_random_sublists(original_list, sublists_info):\n",
    "    result_sublists = []\n",
    "    rng = np.random.default_rng(seed=2020)  # Seed for reproducibility\n",
    "\n",
    "    for length, count in sublists_info.items():\n",
    "        generated_sublists_for_length = set()\n",
    "\n",
    "        while len(generated_sublists_for_length) < count:\n",
    "            sublist = tuple(rng.choice(original_list, length, replace=False))\n",
    "            generated_sublists_for_length.add(sublist)\n",
    "\n",
    "        result_sublists.extend(np.array(list(sublist)) for sublist in generated_sublists_for_length)\n",
    "\n",
    "    return result_sublists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossover and Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def crossover(first_list, second_list, p_cross):\n",
    "    # Find the shorter length among the two lists\n",
    "    length_first = len(first_list)\n",
    "    length_second = len(second_list)\n",
    "    shorter_length = min(length_first, length_second)\n",
    "    \n",
    "    # Compute the number of crossover points\n",
    "    num_crossovers = int(shorter_length * p_cross)\n",
    "    \n",
    "    # Choose random indices for crossover within the range of shorter length\n",
    "    rng = np.random.default_rng(seed=2020)\n",
    "    crossover_indices_first = rng.choice(shorter_length, num_crossovers, replace=False)\n",
    "    crossover_indices_second = rng.choice(shorter_length, num_crossovers, replace=False)\n",
    "    \n",
    "    # Sort the crossover indices\n",
    "    crossover_indices_first.sort()\n",
    "    crossover_indices_second.sort()\n",
    "    \n",
    "    # Swap the elements at the crossover indices\n",
    "    for i in range(num_crossovers):\n",
    "        index_first = crossover_indices_first[i]\n",
    "        index_second = crossover_indices_second[i]\n",
    "        first_list[index_first], second_list[index_second] = second_list[index_second], first_list[index_first]\n",
    "    \n",
    "    return first_list, second_list\n",
    "\n",
    "def mutate_array(org_arr, arr_to_mutate, mutation_probability):\n",
    "    # Calculate the number of elements to mutate\n",
    "    num_mutations = int(mutation_probability * len(arr_to_mutate))\n",
    "    rng = np.random.default_rng(seed=2020)\n",
    "    # Select the indices to mutate\n",
    "    indices_to_mutate = rng.choice(range(len(arr_to_mutate)), size=num_mutations, replace=False)\n",
    "    \n",
    "    # Mutate the selected elements\n",
    "    for idx in indices_to_mutate:\n",
    "        arr_to_mutate[idx] = rng.choice(org_arr)\n",
    "\n",
    "    return arr_to_mutate\n",
    "\n",
    "\n",
    "def remove_duplicates(arr):\n",
    "    _, idx = np.unique(arr, return_index=True)\n",
    "    return arr[np.sort(idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, chain\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "class StaticVars:\n",
    "    FLOAT_MAX = float('inf')\n",
    "\n",
    "def supersets_of_new_subsets_of_old(new_cf, old_cf):\n",
    "    diff = np.setdiff1d(old_cf, new_cf)  # Elements that are in old_cf but not in new_cf\n",
    "    for r in range(1, len(diff) + 1):\n",
    "        for subset in combinations(diff, r):\n",
    "            yield np.union1d(new_cf, subset)\n",
    "\n",
    "def compute_yloss(target_score, kth_score):\n",
    "    yloss = max(0, target_score / kth_score - 1.0)\n",
    "    return yloss\n",
    "\n",
    "def compute_distance(x, y):\n",
    "    diff = np.setdiff1d(x, y)\n",
    "    return len(diff)\n",
    "\n",
    "def compute_loss(old_cf, new_cf, model, target_item, top_k, yloss_cache):\n",
    "    cache_key = frozenset(new_cf)\n",
    "    if cache_key in yloss_cache:\n",
    "        yloss = yloss_cache[cache_key]\n",
    "    else:\n",
    "        new_prediction = model.predict(new_cf)\n",
    "        new_prediction[new_cf] = -StaticVars.FLOAT_MAX\n",
    "        new_rk_data = st.rankdata(-new_prediction, method='ordinal')\n",
    "\n",
    "        top_k_index = np.where(new_rk_data == top_k)[0][0]\n",
    "        yloss = compute_yloss(new_prediction[target_item], new_prediction[top_k_index])\n",
    "        yloss_cache[cache_key] = yloss\n",
    "    dis = compute_distance(old_cf, new_cf)\n",
    "\n",
    "    subset_yloss = 0\n",
    "    for superset in supersets_of_new_subsets_of_old(new_cf, old_cf):\n",
    "        cache_key = frozenset(superset)\n",
    "        if cache_key in yloss_cache:\n",
    "            subset_yloss += yloss_cache[cache_key]\n",
    "        else:\n",
    "            subset_prediction = model.predict(superset)\n",
    "            subset_prediction[superset] = -StaticVars.FLOAT_MAX\n",
    "            sub_rk_data = st.rankdata(-subset_prediction, method='ordinal')\n",
    "            sub_top_k_index = np.where(sub_rk_data == top_k)[0][0]\n",
    "            subset_yloss += compute_yloss(subset_prediction[target_item], subset_prediction[sub_top_k_index])\n",
    "            yloss_cache[cache_key] = subset_yloss\n",
    "\n",
    "    return list([yloss, dis, subset_yloss])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSGA-II\n",
    "Apply NSGA-II to the problem of finding the optimal candicates in multi-objective optimization problem.\n",
    "Based on:\n",
    "- Non-domination Rank\n",
    "- Crowding Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dominates(row, candidateRow):\n",
    "    \"\"\"Determine if one solution dominates another\"\"\"\n",
    "    return all(r <= cr for r, cr in zip(row, candidateRow)) and any(r < cr for r, cr in zip(row, candidateRow))\n",
    "\n",
    "def crowding_distance_assignment(front, values):\n",
    "    distances = [0] * len(values)  # Initialize the distance for every solution as 0\n",
    "    num_objs = len(values[0])\n",
    "    \n",
    "    for m in range(num_objs):\n",
    "        sorted_front = sorted(front, key=lambda x: values[x][m])\n",
    "\n",
    "        # Assign infinite distance at boundaries.\n",
    "        distances[sorted_front[0]] = distances[sorted_front[-1]] = float('inf')\n",
    "\n",
    "        # Normalize the objective values for distance computation.\n",
    "        obj_min = values[sorted_front[0]][m]\n",
    "        obj_max = values[sorted_front[-1]][m]\n",
    "        denom = obj_max - obj_min if obj_max != obj_min else 1\n",
    "\n",
    "        for i in range(1, len(sorted_front) - 1):\n",
    "            distances[sorted_front[i]] += (values[sorted_front[i + 1]][m] - values[sorted_front[i - 1]][m]) / denom\n",
    "\n",
    "    return distances\n",
    "\n",
    "\n",
    "\n",
    "def fast_nondominated_sort(values):\n",
    "    \"\"\"NSGA-II's fast non-dominated sort\"\"\"\n",
    "    S = [[] for _ in range(len(values))]\n",
    "    front = [[]]\n",
    "    n = [0 for _ in range(len(values))]\n",
    "    rank = [-1 for _ in range(len(values))]\n",
    "    \n",
    "    for p in range(len(values)):\n",
    "        S[p] = []\n",
    "        n[p] = 0\n",
    "        for q in range(len(values)):\n",
    "            if dominates(values[p], values[q]):\n",
    "                S[p].append(q)\n",
    "            elif dominates(values[q], values[p]):\n",
    "                n[p] += 1\n",
    "        if n[p] == 0:\n",
    "            rank[p] = 0\n",
    "            front[0].append(p)\n",
    "            \n",
    "    i = 0\n",
    "    while front[i]:\n",
    "        nextFront = []\n",
    "        for p in front[i]:\n",
    "            for q in S[p]:\n",
    "                n[q] = n[q] - 1\n",
    "                if n[q] == 0:\n",
    "                    rank[q] = i + 1\n",
    "                    nextFront.append(q)\n",
    "        i = i + 1\n",
    "        front.append(nextFront)\n",
    "\n",
    "    del front[len(front) - 1]\n",
    "    \n",
    "    # Initialize crowding distances as zeros\n",
    "    crowding_distances = [0] * len(values)\n",
    "    \n",
    "    for front_solutions in front:\n",
    "        current_front_distances = crowding_distance_assignment(front_solutions, values)\n",
    "        for j, solution in enumerate(front_solutions):\n",
    "            crowding_distances[solution] = current_front_distances[solution]\n",
    "    \n",
    "    return rank, crowding_distances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_pairs(list_of_arrays, n):\n",
    "    # Generate all possible pairs\n",
    "    random.seed(2020)\n",
    "    all_pairs = list(itertools.combinations(list_of_arrays, 2))\n",
    "\n",
    "    # Randomly select n pairs\n",
    "    random_pairs = random.sample(all_pairs, n)\n",
    "\n",
    "    return random_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(interaction, candidates, model, target, k, yloss_cache, crossover_p, mutation_p, budget):\n",
    "    # print(len(candidates))\n",
    "    pairs = generate_random_pairs(candidates, len(candidates)//2)\n",
    "    for first, second in pairs:\n",
    "        budget -= 1\n",
    "        first, second = crossover(first, second, crossover_p)\n",
    "        first = mutate_array(interaction, first, mutation_p)\n",
    "        second = mutate_array(interaction, second, mutation_p)\n",
    "        first = remove_duplicates(first)\n",
    "        second = remove_duplicates(second)\n",
    "        candidates.append(first)\n",
    "        candidates.append(second)\n",
    "    # print(len(candidates))\n",
    "    losses = [compute_loss(interaction, arr, model, target, k, yloss_cache) for arr in candidates]\n",
    "    budget -= len(candidates)\n",
    "    # print(losses)\n",
    "    solved = False\n",
    "    solved_list = []\n",
    "    for i in range(len(losses)):\n",
    "        if losses[i][0] == 0:\n",
    "            solved = True\n",
    "            solved_list.append(candidates[i])\n",
    "    if solved:\n",
    "        return solved_list, solved, budget\n",
    "    ranks, crowding_distances = fast_nondominated_sort(losses)\n",
    "    # print(ranks)\n",
    "    candidates_with_metrics = list(zip(candidates, ranks, crowding_distances))\n",
    "\n",
    "    # Sort based on ranks (ascending) and then crowding distances (descending)\n",
    "    candidates_with_metrics.sort(key=lambda x: (x[1], -x[2]))\n",
    "\n",
    "    # Extract candidates after sorting\n",
    "    sorted_candidates = [pair[0] for pair in candidates_with_metrics]\n",
    "\n",
    "    # Extract the top third of candidates\n",
    "    least_loss_arrays = sorted_candidates[:len(sorted_candidates)//2]\n",
    "\n",
    "    return least_loss_arrays, solved, budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model, test_interaction, rank, sublists_info, top_k, crossover_p, mutation_p, budget):\n",
    "    target = get_position_item(model, test_interaction, rank)\n",
    "    new_gen = generate_random_sublists(test_interaction, sublists_info)\n",
    "    budget -= 1\n",
    "    solved = False\n",
    "    yloss_cache = {}\n",
    "    while solved is not True:\n",
    "        new_gen, solved, budget = generation(test_interaction, new_gen, model, target, top_k, yloss_cache, crossover_p, mutation_p, budget)\n",
    "        if budget <= 0:\n",
    "            break\n",
    "    return new_gen, budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "sublists_info ={\n",
    "    8:5,\n",
    "    9:5,\n",
    "    10:5\n",
    "}\n",
    "# main(pooling_model, test_interaction, 1, sublists_info, 10, 0.3, 0.2, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute Force Search\n",
    "Find hard cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def subsets_of_array(arr, k):\n",
    "    if not isinstance(arr, np.ndarray):\n",
    "        raise ValueError(\"Input must be a numpy array\")\n",
    "\n",
    "    n = len(arr)\n",
    "    subsets = []\n",
    "\n",
    "    for size in range(n-1, n-k-1, -1):\n",
    "        combinations = itertools.combinations(arr, size)\n",
    "        for combo in combinations:\n",
    "            subsets.append(np.array(combo))\n",
    "\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_brute(new_cf, model, target_item, top_k, yloss_cache):\n",
    "    cache_key = frozenset(new_cf)\n",
    "    if cache_key in yloss_cache:\n",
    "        yloss = yloss_cache[cache_key]\n",
    "    else:\n",
    "        new_prediction = model.predict(new_cf)\n",
    "        new_prediction[new_cf] = -StaticVars.FLOAT_MAX\n",
    "        new_rk_data = st.rankdata(-new_prediction, method='ordinal')\n",
    "\n",
    "        top_k_index = np.where(new_rk_data == top_k)[0][0]\n",
    "        yloss = compute_yloss(new_prediction[target_item], new_prediction[top_k_index])\n",
    "        yloss_cache[cache_key] = yloss\n",
    "    return yloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brute(candidates, model, target, top_k, yloss_cache):\n",
    "    losses = [compute_loss_brute(arr, model, target, top_k, yloss_cache) for arr in candidates]\n",
    "    solved = False\n",
    "    for i in range(len(losses)):\n",
    "        if losses[i] == 0:\n",
    "            solved = True\n",
    "    return solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brute_main(model, test_interaction, rank, top_k):\n",
    "    target = get_position_item(model, test_interaction, rank)\n",
    "    new_gen = subsets_of_array(test_interaction, 3)\n",
    "    solved = False\n",
    "    yloss_cache = {}\n",
    "    solved = brute(new_gen, model, target, top_k, yloss_cache)\n",
    "    return solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_list = []\n",
    "# for i in range(1000):\n",
    "    # test_interaction = test.sequences[i].copy()\n",
    "    # est_interaction = test_interaction[test_interaction != 0]\n",
    "    # test_interaction.sort()\n",
    "#     for j in range(1, 11):\n",
    "#         solved = brute_main(pooling_model, test_interaction, j, 10)\n",
    "#         if not solved:\n",
    "#             print(i, j)\n",
    "#             final_list.append((i, j))\n",
    "\n",
    "# with open('final_list.txt', 'w') as file:\n",
    "#     for item in final_list:\n",
    "#         file.write(f\"{item[0]}, {item[1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing hard case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858\n",
      "858\n",
      "489\n",
      "489\n",
      "829\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "659\n",
      "788\n",
      "798\n",
      "598\n",
      "659\n",
      "659\n",
      "829\n",
      "-2\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "858\n",
      "858\n",
      "659\n",
      "829\n",
      "-1\n",
      "-1\n",
      "748\n",
      "-1\n",
      "829\n",
      "829\n",
      "149\n",
      "319\n",
      "659\n",
      "659\n",
      "829\n",
      "928\n",
      "829\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "659\n",
      "829\n",
      "548\n",
      "659\n",
      "829\n",
      "829\n",
      "659\n",
      "659\n",
      "659\n",
      "-1\n",
      "848\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "659\n",
      "858\n",
      "829\n",
      "489\n",
      "659\n",
      "768\n",
      "768\n",
      "883\n",
      "898\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "788\n",
      "829\n",
      "-2\n",
      "829\n",
      "-1\n",
      "829\n",
      "659\n",
      "158\n",
      "578\n",
      "-122\n",
      "858\n",
      "848\n",
      "948\n",
      "659\n",
      "-1\n",
      "883\n",
      "653\n",
      "883\n",
      "829\n",
      "788\n",
      "149\n",
      "659\n",
      "489\n",
      "659\n",
      "659\n",
      "829\n",
      "829\n",
      "718\n",
      "928\n",
      "829\n",
      "829\n",
      "659\n",
      "659\n",
      "829\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "748\n",
      "898\n",
      "948\n",
      "-21\n",
      "659\n",
      "659\n",
      "659\n",
      "829\n",
      "659\n",
      "659\n",
      "829\n",
      "319\n",
      "829\n",
      "489\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "858\n",
      "858\n",
      "788\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "829\n",
      "489\n",
      "-47\n",
      "723\n",
      "-47\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "954\n",
      "659\n",
      "829\n",
      "829\n",
      "858\n",
      "858\n",
      "858\n",
      "718\n",
      "578\n",
      "858\n",
      "698\n",
      "798\n",
      "498\n",
      "973\n",
      "973\n",
      "829\n",
      "-2\n",
      "948\n",
      "948\n",
      "-2\n",
      "898\n",
      "659\n",
      "659\n",
      "489\n",
      "829\n",
      "659\n",
      "659\n",
      "489\n",
      "-36\n",
      "909\n",
      "-36\n",
      "149\n",
      "-21\n",
      "319\n",
      "668\n",
      "888\n",
      "943\n",
      "943\n",
      "373\n",
      "659\n",
      "659\n",
      "319\n",
      "489\n",
      "829\n",
      "893\n",
      "963\n",
      "928\n",
      "963\n",
      "909\n",
      "909\n",
      "748\n",
      "873\n",
      "659\n",
      "829\n",
      "-1\n",
      "-1\n",
      "-2\n",
      "-2\n",
      "829\n",
      "659\n",
      "659\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "659\n",
      "549\n",
      "659\n",
      "829\n",
      "829\n",
      "319\n",
      "659\n",
      "829\n",
      "158\n",
      "858\n",
      "858\n",
      "829\n",
      "659\n",
      "829\n",
      "943\n",
      "-1\n",
      "-1\n",
      "718\n",
      "858\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "489\n",
      "829\n",
      "829\n",
      "438\n",
      "158\n",
      "788\n",
      "948\n",
      "948\n",
      "659\n",
      "829\n",
      "829\n",
      "829\n",
      "848\n",
      "898\n",
      "798\n",
      "798\n",
      "898\n",
      "898\n",
      "623\n",
      "659\n",
      "829\n",
      "659\n",
      "149\n",
      "319\n",
      "149\n",
      "659\n",
      "829\n",
      "319\n",
      "829\n",
      "839\n",
      "839\n",
      "599\n",
      "319\n",
      "659\n",
      "829\n",
      "829\n",
      "829\n",
      "943\n",
      "943\n",
      "909\n",
      "928\n",
      "-2\n",
      "829\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "-6\n",
      "909\n",
      "909\n",
      "829\n",
      "718\n",
      "718\n",
      "578\n",
      "858\n",
      "829\n",
      "829\n",
      "659\n",
      "489\n",
      "829\n",
      "829\n",
      "829\n",
      "659\n",
      "659\n",
      "829\n",
      "659\n",
      "829\n",
      "919\n",
      "839\n",
      "919\n",
      "829\n",
      "829\n",
      "819\n",
      "819\n",
      "639\n",
      "369\n",
      "909\n",
      "829\n",
      "829\n",
      "829\n",
      "659\n",
      "919\n",
      "759\n",
      "659\n",
      "398\n",
      "909\n",
      "-36\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "-21\n",
      "659\n",
      "829\n",
      "149\n",
      "659\n",
      "829\n",
      "873\n",
      "873\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "898\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "659\n",
      "829\n",
      "858\n",
      "858\n",
      "698\n",
      "659\n",
      "319\n",
      "659\n",
      "489\n",
      "659\n",
      "659\n",
      "718\n",
      "928\n",
      "369\n",
      "829\n",
      "489\n",
      "848\n",
      "848\n",
      "319\n",
      "829\n",
      "829\n",
      "829\n",
      "149\n",
      "319\n",
      "829\n",
      "659\n",
      "858\n",
      "659\n",
      "829\n",
      "829\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "829\n",
      "659\n",
      "954\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "883\n",
      "829\n",
      "659\n",
      "659\n",
      "829\n",
      "659\n",
      "659\n",
      "659\n",
      "829\n",
      "659\n",
      "659\n",
      "829\n",
      "858\n",
      "858\n",
      "858\n",
      "829\n",
      "659\n",
      "489\n",
      "829\n",
      "829\n",
      "659\n",
      "659\n",
      "829\n",
      "659\n",
      "-1\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "954\n",
      "723\n",
      "-47\n",
      "659\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "659\n",
      "898\n",
      "898\n",
      "829\n",
      "829\n",
      "-1\n",
      "-1\n",
      "-21\n",
      "659\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "319\n",
      "659\n",
      "659\n",
      "659\n",
      "829\n",
      "-81\n",
      "-81\n",
      "639\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "489\n",
      "829\n",
      "659\n",
      "473\n",
      "963\n",
      "819\n",
      "319\n",
      "829\n",
      "-21\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "948\n",
      "848\n",
      "848\n",
      "489\n",
      "489\n",
      "829\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "829\n",
      "848\n",
      "848\n",
      "698\n",
      "548\n",
      "848\n",
      "829\n",
      "489\n",
      "659\n",
      "659\n",
      "829\n",
      "829\n",
      "858\n",
      "659\n",
      "659\n",
      "-21\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "659\n",
      "829\n",
      "698\n",
      "898\n",
      "829\n",
      "829\n",
      "898\n",
      "898\n",
      "883\n",
      "883\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "829\n",
      "538\n",
      "829\n",
      "659\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "149\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "948\n",
      "748\n",
      "873\n",
      "-2\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "659\n",
      "829\n",
      "489\n",
      "829\n",
      "829\n",
      "829\n",
      "489\n",
      "759\n",
      "919\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n",
      "-21\n",
      "659\n",
      "829\n",
      "659\n",
      "829\n",
      "768\n",
      "883\n",
      "873\n",
      "829\n",
      "598\n",
      "798\n",
      "798\n",
      "798\n",
      "829\n",
      "489\n",
      "319\n",
      "659\n",
      "489\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "319\n",
      "829\n",
      "659\n",
      "829\n",
      "639\n",
      "909\n",
      "729\n",
      "909\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "829\n",
      "873\n",
      "-6\n",
      "-2\n",
      "829\n",
      "659\n",
      "829\n",
      "829\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 21\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     sublists_info \u001b[39m=\u001b[39m{\n\u001b[1;32m     16\u001b[0m         length_interaction \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m: length_interaction\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m     17\u001b[0m         length_interaction \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m: length_interaction \u001b[39m*\u001b[39m (length_interaction \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m8\u001b[39m,\n\u001b[1;32m     18\u001b[0m         length_interaction \u001b[39m-\u001b[39m \u001b[39m3\u001b[39m: length_interaction\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m     19\u001b[0m         length_interaction \u001b[39m-\u001b[39m \u001b[39m4\u001b[39m: length_interaction\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m4\u001b[39m\n\u001b[1;32m     20\u001b[0m     }\n\u001b[0;32m---> 21\u001b[0m output, budget \u001b[39m=\u001b[39m main(pooling_model, test_interaction, j, sublists_info, \u001b[39m10\u001b[39;49m, \u001b[39m0.3\u001b[39;49m, \u001b[39m0.2\u001b[39;49m, \u001b[39m1000\u001b[39;49m)\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(budget)\n",
      "Cell \u001b[0;32mIn[136], line 8\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(model, test_interaction, rank, sublists_info, top_k, crossover_p, mutation_p, budget)\u001b[0m\n\u001b[1;32m      6\u001b[0m yloss_cache \u001b[39m=\u001b[39m {}\n\u001b[1;32m      7\u001b[0m \u001b[39mwhile\u001b[39;00m solved \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     new_gen, solved, budget \u001b[39m=\u001b[39m generation(test_interaction, new_gen, model, target, top_k, yloss_cache, crossover_p, mutation_p, budget)\n\u001b[1;32m      9\u001b[0m     \u001b[39mif\u001b[39;00m budget \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     10\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[135], line 14\u001b[0m, in \u001b[0;36mgeneration\u001b[0;34m(interaction, candidates, model, target, k, yloss_cache, crossover_p, mutation_p, budget)\u001b[0m\n\u001b[1;32m     12\u001b[0m     candidates\u001b[39m.\u001b[39mappend(second)\n\u001b[1;32m     13\u001b[0m \u001b[39m# print(len(candidates))\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m losses \u001b[39m=\u001b[39m [compute_loss(interaction, arr, model, target, k, yloss_cache) \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m candidates]\n\u001b[1;32m     15\u001b[0m budget \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(candidates)\n\u001b[1;32m     16\u001b[0m \u001b[39m# print(losses)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[135], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m     candidates\u001b[39m.\u001b[39mappend(second)\n\u001b[1;32m     13\u001b[0m \u001b[39m# print(len(candidates))\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m losses \u001b[39m=\u001b[39m [compute_loss(interaction, arr, model, target, k, yloss_cache) \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m candidates]\n\u001b[1;32m     15\u001b[0m budget \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(candidates)\n\u001b[1;32m     16\u001b[0m \u001b[39m# print(losses)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[132], line 42\u001b[0m, in \u001b[0;36mcompute_loss\u001b[0;34m(old_cf, new_cf, model, target_item, top_k, yloss_cache)\u001b[0m\n\u001b[1;32m     40\u001b[0m     subset_yloss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m yloss_cache[cache_key]\n\u001b[1;32m     41\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     subset_prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(superset)\n\u001b[1;32m     43\u001b[0m     subset_prediction[superset] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mStaticVars\u001b[39m.\u001b[39mFLOAT_MAX\n\u001b[1;32m     44\u001b[0m     sub_rk_data \u001b[39m=\u001b[39m st\u001b[39m.\u001b[39mrankdata(\u001b[39m-\u001b[39msubset_prediction, method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mordinal\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/CFExplainability/spotlight_ext/spotlight/sequence/implicit.py:326\u001b[0m, in \u001b[0;36mImplicitSequenceModel.predict\u001b[0;34m(self, sequences, item_ids)\u001b[0m\n\u001b[1;32m    323\u001b[0m sequence_var \u001b[39m=\u001b[39m gpu(sequences, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_cuda)\n\u001b[1;32m    324\u001b[0m item_var \u001b[39m=\u001b[39m gpu(item_ids, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_cuda)\n\u001b[0;32m--> 326\u001b[0m _, sequence_representations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_net\u001b[39m.\u001b[39;49muser_representation(sequence_var)\n\u001b[1;32m    327\u001b[0m size \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(item_var),) \u001b[39m+\u001b[39m sequence_representations\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    328\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_net(sequence_representations\u001b[39m.\u001b[39mexpand(\u001b[39m*\u001b[39msize),\n\u001b[1;32m    329\u001b[0m                 item_var)\n",
      "File \u001b[0;32m~/Desktop/CFExplainability/spotlight_ext/spotlight/sequence/representations.py:114\u001b[0m, in \u001b[0;36mPoolNet.user_representation\u001b[0;34m(self, item_sequences)\u001b[0m\n\u001b[1;32m    105\u001b[0m non_padding_entries \u001b[39m=\u001b[39m (\n\u001b[1;32m    106\u001b[0m     torch\u001b[39m.\u001b[39mcumsum((sequence_embeddings \u001b[39m!=\u001b[39m \u001b[39m0.0\u001b[39m)\u001b[39m.\u001b[39mfloat(), \u001b[39m2\u001b[39m)\n\u001b[1;32m    107\u001b[0m     \u001b[39m.\u001b[39mexpand_as(sequence_embedding_sum)\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    110\u001b[0m user_representations \u001b[39m=\u001b[39m (\n\u001b[1;32m    111\u001b[0m     sequence_embedding_sum \u001b[39m/\u001b[39m (non_padding_entries \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m    112\u001b[0m )\u001b[39m.\u001b[39msqueeze(\u001b[39m3\u001b[39m)\n\u001b[0;32m--> 114\u001b[0m \u001b[39mreturn\u001b[39;00m user_representations[:, :, :\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], user_representations[:, :, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"final_list.txt\", 'r') as file:\n",
    "    for line in file:\n",
    "        i, j = map(int, line.split(','))\n",
    "        test_interaction = test.sequences[i].copy()\n",
    "        test_interaction = test_interaction[test_interaction != 0]\n",
    "        test_interaction.sort()\n",
    "        length_interaction = len(test_interaction)\n",
    "        if length_interaction <= 1:\n",
    "            continue\n",
    "        elif length_interaction < 5:\n",
    "            sublists_info = {\n",
    "                length_interaction - 1: length_interaction\n",
    "            }\n",
    "        else:\n",
    "            sublists_info ={\n",
    "                length_interaction - 1: length_interaction//2,\n",
    "                length_interaction - 2: length_interaction * (length_interaction - 1) // 8,\n",
    "                length_interaction - 3: length_interaction//3,\n",
    "                length_interaction - 4: length_interaction//4\n",
    "            }\n",
    "        output, budget = main(pooling_model, test_interaction, j, sublists_info, 10, 0.3, 0.2, 1000)\n",
    "        print(budget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m length_interaction \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(test_interaction)\n\u001b[1;32m      6\u001b[0m sublists_info \u001b[39m=\u001b[39m{\n\u001b[1;32m      7\u001b[0m     length_interaction \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m: length_interaction\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m      8\u001b[0m     length_interaction \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m: length_interaction \u001b[39m*\u001b[39m (length_interaction \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m4\u001b[39m,\n\u001b[1;32m      9\u001b[0m     length_interaction \u001b[39m-\u001b[39m \u001b[39m3\u001b[39m: length_interaction\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m     10\u001b[0m     length_interaction \u001b[39m-\u001b[39m \u001b[39m4\u001b[39m: length_interaction\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m4\u001b[39m\n\u001b[1;32m     11\u001b[0m }\n\u001b[0;32m---> 12\u001b[0m output, budget \u001b[39m=\u001b[39m main(pooling_model, test_interaction, \u001b[39m2\u001b[39;49m, sublists_info, \u001b[39m10\u001b[39;49m, \u001b[39m0.3\u001b[39;49m, \u001b[39m0.2\u001b[39;49m, \u001b[39m1000\u001b[39;49m)\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(budget)\n",
      "Cell \u001b[0;32mIn[113], line 8\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(model, test_interaction, rank, sublists_info, top_k, crossover_p, mutation_p, budget)\u001b[0m\n\u001b[1;32m      6\u001b[0m yloss_cache \u001b[39m=\u001b[39m {}\n\u001b[1;32m      7\u001b[0m \u001b[39mwhile\u001b[39;00m solved \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     new_gen, solved, budget \u001b[39m=\u001b[39m generation(test_interaction, new_gen, model, target, top_k, yloss_cache, crossover_p, mutation_p, budget)\n\u001b[1;32m      9\u001b[0m     \u001b[39mif\u001b[39;00m budget \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     10\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[112], line 3\u001b[0m, in \u001b[0;36mgeneration\u001b[0;34m(interaction, candidates, model, target, k, yloss_cache, crossover_p, mutation_p, budget)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgeneration\u001b[39m(interaction, candidates, model, target, k, yloss_cache, crossover_p, mutation_p, budget):\n\u001b[1;32m      2\u001b[0m     \u001b[39m# print(len(candidates))\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     pairs \u001b[39m=\u001b[39m generate_random_pairs(candidates, \u001b[39mlen\u001b[39;49m(candidates)\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m     \u001b[39mfor\u001b[39;00m first, second \u001b[39min\u001b[39;00m pairs:\n\u001b[1;32m      5\u001b[0m         budget \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[111], line 4\u001b[0m, in \u001b[0;36mgenerate_random_pairs\u001b[0;34m(list_of_arrays, n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_random_pairs\u001b[39m(list_of_arrays, n):\n\u001b[1;32m      2\u001b[0m     \u001b[39m# Generate all possible pairs\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     random\u001b[39m.\u001b[39mseed(\u001b[39m2020\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     all_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mcombinations(list_of_arrays, \u001b[39m2\u001b[39;49m))\n\u001b[1;32m      6\u001b[0m     \u001b[39m# Randomly select n pairs\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     random_pairs \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msample(all_pairs, n)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_interaction = test.sequences[24].copy()\n",
    "test_interaction = test_interaction[test_interaction != 0]\n",
    "test_interaction.sort()\n",
    "print(test_interaction)\n",
    "length_interaction = len(test_interaction)\n",
    "sublists_info ={\n",
    "    length_interaction - 1: length_interaction//2,\n",
    "    length_interaction - 2: length_interaction * (length_interaction - 1) // 4,\n",
    "    length_interaction - 3: length_interaction//3,\n",
    "    length_interaction - 4: length_interaction//4\n",
    "}\n",
    "output, budget = main(pooling_model, test_interaction, 2, sublists_info, 10, 0.3, 0.2, 1000)\n",
    "print(budget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
