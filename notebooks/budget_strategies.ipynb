{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats as st\n",
    "import itertools\n",
    "import operator\n",
    "\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb')\n",
    "%run $helpers_file\n",
    "\n",
    "# # load the autoreload extension\n",
    "# %load_ext autoreload\n",
    "# # Set extension to reload modules every time before executing code\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['../spotlight_ext']:\n",
    "    module_path = os.path.abspath(os.path.join(base_dir, p))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "random_state = np.random.RandomState(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "## !jupyter nbconvert budget_strategies.ipynb --no-input --no-prompt --to pdf\n",
    "# os.system(\"jupyter nbconvert budget_strategies.ipynb --no-input --no-prompt --to pdf\")\n",
    "# os.system(\"jupyter nbconvert budget_strategies.ipynb --config ~/.jupyter/jupyter_nbconvert_config.py --to slides\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare models/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implicit_model = load_model('implicit_factorization')\n",
    "lstm_model = load_model(model_type='entire')\n",
    "pooling_model = load_model('pooling')\n",
    "\n",
    "pretrained_models = {\n",
    "    'lstm': lstm_model,\n",
    "    'pooling': pooling_model,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "\n",
    "# get dataset\n",
    "dataset = get_movielens_dataset(variant='1M')\n",
    "train, test = random_train_test_split(dataset, random_state=random_state)\n",
    "\n",
    "max_sequence_length = 20\n",
    "train = train.to_sequence(max_sequence_length=max_sequence_length)\n",
    "test = test.to_sequence(max_sequence_length=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__main__\n"
     ]
    }
   ],
   "source": [
    "print(compute_sim_matrix.__module__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a871cff3ef4d51aaeb6ac3cf687bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pooling_sims_matrix = gpu_embeddings_to_cosine_similarity_matrix(\n",
    "    pooling_model._net.item_embeddings(\n",
    "        torch.arange(0, dataset.num_items, dtype=torch.int64)\n",
    "    )).detach().numpy()\n",
    "\n",
    "jaccard_sims_matrix = compute_sim_matrix(dataset, 'jaccard')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various implemented Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseStrategy:\n",
    "    class_name = None\n",
    "\n",
    "    def __init__(self, item, interactions, max_length, init_budget, model=None, random_pick=False):\n",
    "\n",
    "        self.target_item = item\n",
    "        self.original_interactions = interactions\n",
    "        self.max_length = max_length\n",
    "        self.visited_ = set()\n",
    "        self.model = model\n",
    "        self.last_comb_cost = 0\n",
    "        self.random_pick = random_pick\n",
    "        self.top_k = 10\n",
    "\n",
    "        self.budget = init_budget\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _get_pos(self, number):\n",
    "        bits = []\n",
    "        for i, c in enumerate(bin(number)[:1:-1], 1):\n",
    "            if c == '0':\n",
    "                bits.append(i)\n",
    "        return bits\n",
    "\n",
    "    def reset_costs(self):\n",
    "        self.last_comb_cost = 0\n",
    "\n",
    "    def get_init_budget(self):\n",
    "        return self.budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSelection(BaseStrategy):\n",
    "    class_name = 'Random'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget)\n",
    "\n",
    "    def _next_item(self):\n",
    "        self.budget -= 1\n",
    "\n",
    "        #         number = np.random.choice(np.setdiff1d(range(1, pow(2, self.max_length)), self.visited_))\n",
    "        number = random.sample(range(1, pow(2, self.max_length)), 1)[0]\n",
    "        while number in self.visited_:\n",
    "            number = random.sample(range(1, pow(2, self.max_length)), 1)[0]\n",
    "        self.visited_.add(number)\n",
    "        return number\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        number = self._next_item()\n",
    "\n",
    "        bits = self._get_pos(number)\n",
    "        seq = np.delete(self.original_interactions, bits)\n",
    "\n",
    "        return (seq, self.budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MostSimilarSelection(BaseStrategy):\n",
    "    class_name = 'Sim-Matrix'\n",
    "\n",
    "    supported_sim_matrix = {\n",
    "        'pooling': pooling_sims_matrix,\n",
    "        'jaccard': jaccard_sims_matrix\n",
    "    }\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, model, sim_type='pooling'):\n",
    "        super().__init__(item, interactions, max_sequence_length)\n",
    "\n",
    "        self.visited_.add(0)\n",
    "        self.reverse_checks = []\n",
    "        self.is_materialized = False\n",
    "\n",
    "        self._get_sim_ranking(sim_type)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        if reverse:\n",
    "            self._materialize_list()\n",
    "            selected_item_indices = self.reverse_checks.pop(\n",
    "                random.randrange(len(self.reverse_checks)) if self.random_pick else 0\n",
    "            ) if len(self.reverse_checks) else []\n",
    "        else:\n",
    "            self.visited_.add(max(self.visited_) + 1)\n",
    "            selected_item_indices = np.where(np.isin(\n",
    "                self.rk_items,\n",
    "                list(set(self.rk_items).difference(set(self.visited_)))\n",
    "            ))[0]\n",
    "        seq = self.original_interactions[selected_item_indices] if len(selected_item_indices) else None\n",
    "        return seq\n",
    "\n",
    "    def _get_sim_ranking(self, sim_type):\n",
    "        ranked_items = st.rankdata(self.supported_sim_matrix[sim_type][self.target_item, self.original_interactions])\n",
    "        self.rk_items = self.max_length - ranked_items + 1\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        if not self.is_materialized:\n",
    "            psize = len(self.visited_) - 1  # do not consider initial added zero value\n",
    "            # do not take account none/all excluded interacted items\n",
    "            prods = sorted(list(map(list, itertools.product([0, 1], repeat=psize)))[1:-1], key=sum)\n",
    "#             last_item_indices = np.where(np.isin(\n",
    "#                 self.rk_items,\n",
    "#                 list(set(self.rk_items).difference(set(self.visited_)))\n",
    "#             ))\n",
    "\n",
    "            lvisited_ = np.asarray(list(self.visited_))[1:]\n",
    "            for p in prods:\n",
    "                self.reverse_checks.append(np.where(np.isin(\n",
    "                    self.rk_items,\n",
    "                    list(set(self.rk_items).difference(lvisited_[np.nonzero(np.multiply(p, lvisited_))])))\n",
    "                ))\n",
    "\n",
    "            self.is_materialized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MostSimilarSelectionByJaccard(MostSimilarSelection):\n",
    "    class_name = 'Jaccard-on-Sim-Matrix'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model, 'jaccard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class RandomMostSimilarSelection(MostSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.random_pick = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossSimilarSelection(BaseStrategy):\n",
    "    class_name = 'BFS'\n",
    "\n",
    "#     def next_comb(self, reverse=False):\n",
    "#         if reverse:\n",
    "#             self._materialize_list()\n",
    "#         else:\n",
    "#             self._get_sim_ranking()\n",
    "\n",
    "#         seq = np.ma.compressed(self.ma_arr)\n",
    "#         return seq if len(seq) else None\n",
    "\n",
    "#     def compute_losses(self, inv_mask=False):\n",
    "#         res = []\n",
    "#         self.last_comb_cost = 0\n",
    "\n",
    "#         m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "#         tmp_ma_arr = np.ma.masked_array(self.original_interactions, mask=np.logical_not(m_mask) if inv_mask else m_mask)\n",
    "#         for idx in tmp_ma_arr.nonzero()[0]:\n",
    "#             m_mask[idx] = not m_mask[idx]\n",
    "#             if np.any(np.invert(m_mask)):\n",
    "#                 perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=m_mask))\n",
    "\n",
    "#                 # predict next top-k items about to be selected\n",
    "#                 preds = self.model.predict(perm)\n",
    "#                 preds[perm] = -StaticVars.FLOAT_MAX\n",
    "#                 t_score = preds[self.target_item]\n",
    "#                 res.append([t_score, idx])\n",
    "\n",
    "#                 self.last_comb_cost += 1\n",
    "# #             else: res.append([0, -1])\n",
    "\n",
    "#             m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "#         return res\n",
    "\n",
    "#     def _materialize_list(self):\n",
    "#         if not self.is_materialized:\n",
    "#             m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "#             psize = sum(m_mask)\n",
    "#             # do not take account none/all excluded interacted items\n",
    "#             prods = sorted(list(map(list, itertools.product([0, 1], repeat=psize)))[1:-1], key=sum)\n",
    "\n",
    "#             lvisited_ = np.where(m_mask == True)[0]\n",
    "#             for p in prods:\n",
    "#                 curr_mask = np.ma.getmaskarray(self.ma_arr).copy()\n",
    "#                 curr_mask[lvisited_[np.nonzero(np.multiply(p, lvisited_))]] = 0\n",
    "\n",
    "#                 self.reverse_checks.append(curr_mask)\n",
    "\n",
    "#             self.is_materialized = True\n",
    "\n",
    "#         m_mask = self.reverse_checks.pop(\n",
    "#             random.randrange(len(self.reverse_checks)) if self.random_pick else 0\n",
    "#         ) if len(self.reverse_checks) else True\n",
    "#         self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, early_term=False):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        self.q = Queue()\n",
    "        self.q.enqueue(([False] * len(self.original_interactions), StaticVars.INT_MAX, 0))\n",
    "\n",
    "        self.thres = len(self.original_interactions) + 1\n",
    "        self.early_termination = early_term\n",
    "\n",
    "    def _update_queue(self, is_solved):\n",
    "        self.compute_loss(is_solved)\n",
    "\n",
    "    def _next_item(self):\n",
    "        mask, t_score, is_solved = self.q.dequeue()\n",
    "        while self.early_termination and sum(mask) == self.thres:\n",
    "            q_data = self.q.dequeue()\n",
    "            if q_data is None: break\n",
    "\n",
    "            mask, t_score, is_solved = q_data\n",
    "\n",
    "        if is_solved == 2:\n",
    "            t_score, kth_score = self.get_score(mask)\n",
    "\n",
    "            if (t_score / kth_score) < 1: self.thres = sum(mask)\n",
    "\n",
    "        return (is_solved, mask, self.budget)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if self.q.size() > 0:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "            self._update_queue(solved_flag)\n",
    "        else: self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    def compute_loss(self, is_solved=False):\n",
    "        self.last_comb_cost = 0\n",
    "\n",
    "        if not is_solved: self.search(forward=True, s=is_solved)\n",
    "        else: self.search(forward=False, s=is_solved)\n",
    "\n",
    "    def search(self, forward=True, s=False):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask) if forward else m_mask)[0]\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask, s)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    def get_score(self, d):\n",
    "        perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "\n",
    "        self.budget -= 1\n",
    "        # predict next top-k items about to be selected\n",
    "        preds = self.model.predict(perm)\n",
    "        preds[perm] = -StaticVars.FLOAT_MAX\n",
    "        rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "        return (preds[self.target_item], preds[(rk_data == self.top_k).nonzero()][0])\n",
    "\n",
    "    def add(self, d, s):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "\n",
    "            if not s:\n",
    "                t_score, kth_score = self.get_score(d)\n",
    "\n",
    "                if self.q.size() == 0: self.q.enqueue((d.copy(), t_score, 1 if (t_score / kth_score) < 1 else 0))\n",
    "\n",
    "                if t_score < self.q.get(0)[1]:  # get only the assigned score\n",
    "                    self.q.setter(0, (d.copy(), t_score, 1 if (t_score / kth_score) < 1 else 0))\n",
    "            else:\n",
    "                self.q.enqueue((d.copy(), StaticVars.INT_MAX, 2))\n",
    "\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFSwithLossSelection(LossSimilarSelection):\n",
    "    class_name = 'DFS'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.candidate_solutions = Stack()\n",
    "\n",
    "    def _get_sim_ranking(self):\n",
    "        res = self.compute_losses()\n",
    "\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        m_mask[min(res, key=lambda item: item[0])[1]] = True\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "\n",
    "        if np.sum(m_mask) > 1:\n",
    "            res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "            for idx in sorted(res, key=lambda item: item[0], reverse=True):\n",
    "                m_mask[idx[1]] = False\n",
    "                self.candidate_solutions.push(m_mask.copy())\n",
    "                m_mask[idx[1]] = True\n",
    "\n",
    "        m_mask = self.candidate_solutions.pop()\n",
    "        while m_mask is not None and int(''.join(map(str, m_mask.astype(int))), 2) in self.visited_:\n",
    "            m_mask = self.candidate_solutions.pop()\n",
    "\n",
    "        self.visited_.add(0 if m_mask is None else int(''.join(map(str, m_mask.astype(int))), 2))\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True if m_mask is None else m_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class RandomLossSimilarSelection(LossSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.random_pick = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class FixedRankingLossSimilarSelection(LossSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.rk_items = []\n",
    "        self._get_sim_ranking()\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        if reverse:\n",
    "            self._materialize_list()\n",
    "        else:\n",
    "            m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "            m_mask[self.rk_items.pop(0)] = True\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return seq if len(seq) else None\n",
    "\n",
    "    def _get_sim_ranking(self):\n",
    "        res = self.compute_losses()\n",
    "\n",
    "        ranked_items = np.asarray(res).argsort(axis=0)\n",
    "        self.rk_items = [item[0] for item in ranked_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import heapq as hq\n",
    "\n",
    "\n",
    "class BestFSLossSelection(LossSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.set = set()\n",
    "        self.tiebraker = itertools.count()\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "\n",
    "        if not self.is_materialized:\n",
    "            if np.sum(m_mask) > 1:\n",
    "                res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "                for idx in res:\n",
    "                    m_mask[idx[1]] = False\n",
    "                    self.reverse_checks.append((idx[0], next(self.tiebraker), m_mask.copy()))\n",
    "                    self.set.add(int(''.join(map(str, m_mask.copy().astype(int))), 2))\n",
    "                    m_mask[idx[1]] = True\n",
    "\n",
    "                hq.heapify(self.reverse_checks)\n",
    "\n",
    "            self.is_materialized = True\n",
    "\n",
    "        _, _, m_mask = hq.heappop(self.reverse_checks) if len(self.reverse_checks) > 0 else (None, None, True)\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "        if np.sum(m_mask) > 1:\n",
    "            m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "            res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "            for idx in res:\n",
    "                m_mask[idx[1]] = False\n",
    "                self.add(m_mask.copy(), idx[0])\n",
    "                m_mask[idx[1]] = True\n",
    "\n",
    "    def add(self, d, pri):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if mask_to_int not in self.set:\n",
    "            hq.heappush(self.reverse_checks, (pri, next(self.tiebraker), d))\n",
    "            self.set.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import heapq as hq\n",
    "\n",
    "\n",
    "class TopDownBestFSLossSelection(LossSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.best_score_per_cardinality = [StaticVars.FLOAT_MAX] * self.max_length\n",
    "        self.set = set()\n",
    "        self.tiebraker = itertools.count()\n",
    "\n",
    "    def set_score(self, cardinality, target_score, kth_score):\n",
    "        reverse_search = False\n",
    "        score = target_score / kth_score\n",
    "        if score < self.best_score_per_cardinality[cardinality]:\n",
    "            self.best_score_per_cardinality[cardinality] = score\n",
    "\n",
    "            if score > 1.0: reverse_search = True\n",
    "\n",
    "        return reverse_search\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "\n",
    "        if not self.is_materialized:\n",
    "            if np.sum(m_mask) > 1:\n",
    "                res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "                for idx in res:\n",
    "                    m_mask[idx[1]] = False\n",
    "                    self.reverse_checks.append((idx[0], next(self.tiebraker), m_mask.copy()))\n",
    "                    self.set.add(int(''.join(map(str, m_mask.copy().astype(int))), 2))\n",
    "                    m_mask[idx[1]] = True\n",
    "\n",
    "                hq.heapify(self.reverse_checks)\n",
    "\n",
    "            self.is_materialized = True\n",
    "\n",
    "        _, _, m_mask = hq.heappop(self.reverse_checks) if len(self.reverse_checks) > 0 else (None, None, True)\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "        if np.sum(m_mask) > 1:\n",
    "            m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "            res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "            for idx in res:\n",
    "                m_mask[idx[1]] = False\n",
    "                self.add(m_mask.copy(), idx[0])\n",
    "                m_mask[idx[1]] = True\n",
    "\n",
    "    def add(self, d, pri):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if mask_to_int not in self.set:\n",
    "            hq.heappush(self.reverse_checks, (pri, next(self.tiebraker), d))\n",
    "            self.set.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class DFSwithFixedRankingLossSelection(FixedRankingLossSimilarSelection):\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        if reverse:\n",
    "            self._materialize_list()\n",
    "        else:\n",
    "            m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "            m_mask[self.rk_items.pop(0)] = True\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return seq if len(seq) else None\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "\n",
    "        if np.sum(m_mask) > 1:\n",
    "            res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "            if not self.is_materialized:\n",
    "                for idx in sorted(res, key=lambda item: item[0]):\n",
    "                    m_mask[idx[1]] = False\n",
    "                    self.reverse_checks.append(m_mask.copy())\n",
    "                    m_mask[idx[1]] = True\n",
    "\n",
    "                self.is_materialized = True\n",
    "            else:\n",
    "                m_mask[min(res, key=lambda item: item[0])[1]] = False\n",
    "                self.reverse_checks.insert(0, m_mask)\n",
    "\n",
    "        m_mask = self.reverse_checks.pop(\n",
    "            random.randrange(len(self.reverse_checks)) if self.random_pick else 0\n",
    "        ) if len(self.reverse_checks) else True\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import heapq as hq\n",
    "\n",
    "\n",
    "class BestFSFixedLossSelection(FixedRankingLossSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.best_score_per_cardinality = [-StaticVars.FLOAT_MAX] * self.max_length\n",
    "        self.set = set()\n",
    "        self.tiebraker = itertools.count()\n",
    "\n",
    "#     is not currently used\n",
    "#     def set_score(self, cardinality, target_score, kth_score):\n",
    "#         is_updated = False\n",
    "#         if self.best_score_per_cardinality[cardinality] > (target_score / kth_score):\n",
    "#             self.best_score_per_cardinality[cardinality] = target_score / kth_score\n",
    "#             is_updated = True\n",
    "\n",
    "#         return is_updated\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "\n",
    "        if not self.is_materialized:\n",
    "            if np.sum(m_mask) > 1:\n",
    "                res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "                for idx in res:\n",
    "                    m_mask[idx[1]] = False\n",
    "                    self.reverse_checks.append((idx[0], next(self.tiebraker), m_mask.copy()))\n",
    "                    self.set.add(int(''.join(map(str, m_mask.copy().astype(int))), 2))\n",
    "                    m_mask[idx[1]] = True\n",
    "\n",
    "                hq.heapify(self.reverse_checks)\n",
    "\n",
    "            self.is_materialized = True\n",
    "\n",
    "        _, _, m_mask = hq.heappop(self.reverse_checks) if len(self.reverse_checks) > 0 else (None, None, True)\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "        if np.sum(m_mask) > 1:\n",
    "            m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "            res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "            for idx in res:\n",
    "                m_mask[idx[1]] = False\n",
    "                self.add(m_mask.copy(), idx[0])\n",
    "                m_mask[idx[1]] = True\n",
    "\n",
    "    def add(self, d, pri):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if mask_to_int not in self.set:\n",
    "            hq.heappush(self.reverse_checks, (pri, next(self.tiebraker), d))\n",
    "            self.set.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiDirectionalSelection(BaseStrategy):\n",
    "    class_name = 'BiDirectional'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, weights=(1, 0), alpha=0.9, normalization='default'):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        self.tiebraker = itertools.count()\n",
    "        self.q = [(1, StaticVars.INT_MAX, next(self.tiebraker), [False] * len(self.original_interactions), self.budget)]\n",
    "        hq.heapify(self.q)\n",
    "\n",
    "#         self.w_loss, self.w_custom = weights if len(weights) == 2 else (1, 0)\n",
    "        self.alpha = alpha\n",
    "        self.norm = normalization\n",
    "\n",
    "    def _update_queue(self, is_solved):\n",
    "        self.compute_loss(is_solved)\n",
    "\n",
    "    def _next_item(self):\n",
    "        is_solved, _, _, mask, budget = hq.heappop(self.q)\n",
    "        return (is_solved, mask, budget)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "        if self.q:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "            self._update_queue(solved_flag)\n",
    "        else: self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    def compute_loss(self, is_solved=False):\n",
    "        self.search(forward=True, s=is_solved)\n",
    "        self.search(forward=False, s=is_solved)\n",
    "\n",
    "    def search(self, forward=True, s=False):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask) if forward else m_mask)[0]\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask, s)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    def get_custom_score(self, c):\n",
    "#         return self.w_custom * (c / self.max_length)\n",
    "        return c / self.max_length\n",
    "\n",
    "    def get_score(self, d):\n",
    "        self.budget -= 1\n",
    "\n",
    "        # predict next top-k items about to be selected\n",
    "        perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "        preds = self.model.predict(perm)\n",
    "\n",
    "        if self.norm == 'kth_norm':\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "            rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "            t_score = preds[self.target_item] / preds[(rk_data == self.top_k).nonzero()][0]\n",
    "        elif self.norm == 'rescale':\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "            rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "            max_val = rk_data[0]\n",
    "            min_val = rk_data[-1]\n",
    "            t_score = (max_val - preds[self.target_item]) / (max_val - min_val)\n",
    "        else:  # default case\n",
    "            tensor = F.softmax(torch.from_numpy(preds).float(), dim=0)\n",
    "            preds = tensor.numpy()\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "\n",
    "            t_score = preds[self.target_item]\n",
    "\n",
    "        return self.alpha * t_score + (1 - self.alpha) * self.get_custom_score(np.sum(d))\n",
    "\n",
    "    def add(self, d, s):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            t_score = self.get_score(d)\n",
    "            hq.heappush(self.q, (int(not s), t_score, next(self.tiebraker), d.copy(), self.budget))\n",
    "\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class BruteForceSelection(BaseStrategy):\n",
    "    class_name = 'BruteForce'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        self.q = Queue()\n",
    "        self.q.enqueue(([False] * len(self.original_interactions), self.budget))\n",
    "\n",
    "    def _expand_queue(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask))[0]\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    def _next_item(self):\n",
    "        mask, budget = self.q.dequeue()\n",
    "        return (mask, budget)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if reverse: self.q.clear()\n",
    "\n",
    "        if self.q.size() > 0:\n",
    "            item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "            self._expand_queue()\n",
    "        else:\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    def add(self, d):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            self.budget -= 1\n",
    "            self.q.enqueue((d.copy(), self.budget))\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComboSelection(BiDirectionalSelection):\n",
    "    class_name = 'Combo'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, weights=(1, 0), alpha=0.9, normalization='default'):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model, weights, alpha, normalization)\n",
    "\n",
    "        self.alpha = 1\n",
    "\n",
    "        self.q_init = Queue()\n",
    "        self.q_init.enqueue((StaticVars.INT_MAX, [False] * len(self.original_interactions), self.budget))\n",
    "        self.init_queue()\n",
    "\n",
    "        self.tiebraker = itertools.count()\n",
    "        self.q = []\n",
    "        hq.heapify(self.q)\n",
    "\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def init_queue(self):\n",
    "        _, m_mask, budget = self.q_init.dequeue()\n",
    "        m_mask = np.asarray(m_mask)\n",
    "\n",
    "        valid_items = np.where(np.logical_not(m_mask))[0]\n",
    "        for idx in valid_items:\n",
    "            m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "            mask_to_int = int(''.join(map(str, m_mask.astype(int))), 2)\n",
    "            if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "                t_score = self.get_score(m_mask)\n",
    "                self.q_init.enqueue((t_score, m_mask.copy(), self.budget))\n",
    "\n",
    "                self.visited_.add(mask_to_int)\n",
    "\n",
    "            m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "        pair_combs = []\n",
    "        for c in itertools.combinations(range(len(self.original_interactions)), 2):\n",
    "            m = [False] * len(self.original_interactions)\n",
    "            m[c[0]], m[c[1]] = not m[c[0]], not m[c[1]]\n",
    "            pair_combs.append((self.q_init.get(c[0])[0] + self.q_init.get(c[1])[0], m.copy()))\n",
    "\n",
    "        pair_combs.sort(key=operator.itemgetter(0))\n",
    "        for c in pair_combs:\n",
    "            self.budget -= 1\n",
    "            self.q_init.enqueue((0, c[1], self.budget))\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if self.q_init.size() > 0:\n",
    "            s, item_mask, budget = self.q_init.dequeue()\n",
    "            item_mask = np.asarray(item_mask)\n",
    "            solved_flag = False\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "\n",
    "            self.add(item_mask, False)\n",
    "        elif self.q:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "\n",
    "            self._update_queue(solved_flag)\n",
    "        else: self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_backend_strategy(backend):\n",
    "    if 'random' == backend:\n",
    "        return RandomSelection\n",
    "    elif 'most_sim' == backend:\n",
    "        return MostSimilarSelection\n",
    "    elif 'most_sim_jaccard' == backend:\n",
    "        return MostSimilarSelectionByJaccard\n",
    "    elif 'bfs' == backend:\n",
    "        return LossSimilarSelection\n",
    "    elif 'random_most_sim' == backend:\n",
    "        return RandomMostSimilarSelection\n",
    "    elif 'random_loss_sim' == backend:\n",
    "        return RandomLossSimilarSelection\n",
    "    elif 'fixed_loss_sim' == backend:\n",
    "        return FixedRankingLossSimilarSelection\n",
    "    elif 'dfs_loss_sim' == backend:\n",
    "        return DFSwithLossSelection\n",
    "    elif 'dfs_fixed_loss_sim' == backend:\n",
    "        return DFSwithFixedRankingLossSelection\n",
    "    elif 'bestFS_loss' == backend:\n",
    "        return BestFSLossSelection\n",
    "    elif 'bestFS_fixed_loss' == backend:\n",
    "        return BestFSFixedLossSelection\n",
    "    elif 'topdown_loss' == backend:\n",
    "        return TopDownBestFSLossSelection\n",
    "    elif 'bidirectional' == backend:\n",
    "        return BiDirectionalSelection\n",
    "    elif 'brute_force' == backend:\n",
    "        return BruteForceSelection\n",
    "    elif 'combo' == backend:\n",
    "        return ComboSelection\n",
    "    else: print('Unknown strategy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution of implemented strategies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategies inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_applied = 'lstm'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: Random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7266f0e05f794aecad1a7af08ca1fb80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 10it [00:55,  5.54s/it]              \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m backend \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrandom\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m random_cfs \u001b[39m=\u001b[39m [\n\u001b[0;32m----> 3\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39;49m\u001b[39mlstm\u001b[39;49m\u001b[39m'\u001b[39;49m], get_backend_strategy(backend), [\u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m, \u001b[39m5\u001b[39;49m, \u001b[39m7\u001b[39;49m], no_users\u001b[39m=\u001b[39;49m\u001b[39m6000\u001b[39;49m, init_budget\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m),\n\u001b[1;32m      4\u001b[0m \u001b[39m#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='random', init_budget=1000)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      7\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mstore\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrandom_cfs\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/var/folders/v1/m2nqhx3d4yv9mjbpndrlsck00000gn/T/ipykernel_41760/2050766523.py:87\u001b[0m, in \u001b[0;36m_find_cfs\u001b[0;34m(dataset, model, strategy_func, target_item_pos, no_users, init_budget, max_allowed_permutations, top_k, total_CFs, num_processes, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m             best_tot_loss_data[pos] \u001b[39m=\u001b[39m []\n\u001b[1;32m     85\u001b[0m             \u001b[39mfor\u001b[39;00m user_id \u001b[39min\u001b[39;00m trange(\u001b[39m1\u001b[39m, num_users \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39musers loop\u001b[39m\u001b[39m'\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):  \u001b[39m# dataset.num_users):\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[39m#                 best_tot_loss_data[pos].append(_total_loss)\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m                 best_tot_loss_data[pos]\u001b[39m.\u001b[39mextend(_retrieve_solutions((\n\u001b[1;32m     88\u001b[0m                     user_id, dataset, model, strategy_func, pos, init_budget, top_k, kwargs)))\n\u001b[1;32m     91\u001b[0m \u001b[39m#         pool = Pool(processes=min(num_processes, cpu_count() - 1, 4), initargs=(RLock(),), initializer=tqdm.set_lock)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m#         with Pool(processes=min(num_processes, cpu_count() - 1, 2), initializer=init, initargs=(l,)) as pool:\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[39m#         jobs = [pool.apply_async(_retrieve_solutions, args=((n,dataset,model,strategy_func,pos,init_budget,top_k,kwargs),)) \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m#                 )), total=num_users))\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m# #                 r = list(tqdm(p.imap(_foo, range(30)), total=30))\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m best_tot_loss_data\n",
      "File \u001b[0;32m/var/folders/v1/m2nqhx3d4yv9mjbpndrlsck00000gn/T/ipykernel_41760/2050766523.py:43\u001b[0m, in \u001b[0;36m_retrieve_solutions\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 preds[perm] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mStaticVars\u001b[39m.\u001b[39mFLOAT_MAX\n\u001b[1;32m     33\u001b[0m                 \u001b[39m# already taken care in strategy func, so do not count. \u001b[39;00m\n\u001b[1;32m     34\u001b[0m                 \u001b[39m# We exec model again to retrieve useful info to store\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m#                 budget -= 1  # used Query\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m# #                             tensor = F.softmax(tensor, dim=0)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m#                             print('after', tensor, F.softmax(tensor, dim=-1), torch.max(tensor))\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m                 rk_data \u001b[39m=\u001b[39m st\u001b[39m.\u001b[39;49mrankdata(\u001b[39m-\u001b[39;49mpreds, method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mordinal\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     44\u001b[0m                 computed_loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mcompute_loss(perm, preds, rk_data)\n\u001b[1;32m     45\u001b[0m \u001b[39m#                             print('stats', user_id, computed_loss, len(perm), rk_data[target_item])\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \n\u001b[1;32m     47\u001b[0m                 \u001b[39m# keep info about the best solution found depending on an objective function\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/scipy/stats/_stats_py.py:9505\u001b[0m, in \u001b[0;36mrankdata\u001b[0;34m(a, method, axis, nan_policy)\u001b[0m\n\u001b[1;32m   9502\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mfull_like(arr, np\u001b[39m.\u001b[39mnan)\n\u001b[1;32m   9504\u001b[0m algo \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmergesort\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mordinal\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mquicksort\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m-> 9505\u001b[0m sorter \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49margsort(arr, kind\u001b[39m=\u001b[39;49malgo)\n\u001b[1;32m   9507\u001b[0m inv \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(sorter\u001b[39m.\u001b[39msize, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n\u001b[1;32m   9508\u001b[0m inv[sorter] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(sorter\u001b[39m.\u001b[39msize, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margsort\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/core/fromnumeric.py:1146\u001b[0m, in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[1;32m   1039\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39margsort\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, kind\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1040\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[39m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \n\u001b[1;32m   1145\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1146\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39margsort\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49maxis, kind\u001b[39m=\u001b[39;49mkind, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "backend = 'random'\n",
    "random_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='random', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store random_cfs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Most Similar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_find_cfs() missing 1 required positional argument: 'strategy_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[144], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cosine_on_embeddings_cfs \u001b[39m=\u001b[39m [\n\u001b[0;32m----> 2\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39;49m\u001b[39mlstm\u001b[39;49m\u001b[39m'\u001b[39;49m], target_item_pos \u001b[39m=\u001b[39;49m [\u001b[39m3\u001b[39;49m, \u001b[39m5\u001b[39;49m, \u001b[39m7\u001b[39;49m], no_users\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, backend\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmost_sim\u001b[39;49m\u001b[39m'\u001b[39;49m, init_budget\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m),\n\u001b[1;32m      3\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39m\u001b[39mpooling\u001b[39m\u001b[39m'\u001b[39m], get_backend_strategy(\u001b[39m'\u001b[39m\u001b[39mmost_sim\u001b[39m\u001b[39m'\u001b[39m), [\u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m7\u001b[39m], no_users\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, backend\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmost_sim\u001b[39m\u001b[39m'\u001b[39m, init_budget\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m)\n\u001b[1;32m      4\u001b[0m ]\n\u001b[1;32m      5\u001b[0m jaccard_on_embeddings_cfs \u001b[39m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39m\u001b[39mlstm\u001b[39m\u001b[39m'\u001b[39m], [\u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m7\u001b[39m], no_users\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, backend\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmost_sim_jaccard\u001b[39m\u001b[39m'\u001b[39m, init_budget\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m),\n\u001b[1;32m      7\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39m\u001b[39mpooling\u001b[39m\u001b[39m'\u001b[39m], [\u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m7\u001b[39m], no_users\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, backend\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmost_sim_jaccard\u001b[39m\u001b[39m'\u001b[39m, init_budget\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m),\n\u001b[1;32m      8\u001b[0m ]\n\u001b[1;32m     10\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mstore\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcosine_on_embeddings_cfs\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: _find_cfs() missing 1 required positional argument: 'strategy_func'"
     ]
    }
   ],
   "source": [
    "cosine_on_embeddings_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], target_item_pos = [3, 5, 7], no_users=500, backend='most_sim', init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['pooling'], get_backend_strategy('most_sim'), [3, 5, 7], no_users=500, backend='most_sim', init_budget=1000)\n",
    "]\n",
    "jaccard_on_embeddings_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], [3, 5, 7], no_users=500, backend='most_sim_jaccard', init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='most_sim_jaccard', init_budget=1000),\n",
    "]\n",
    "\n",
    "%store cosine_on_embeddings_cfs\n",
    "%store jaccard_on_embeddings_cfs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilize ylosses for similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BFS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf2413a7bd643f2b15678c0a1db3cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_budget is  1000\n",
      "1\n",
      "init_budget is  1000\n",
      "2\n",
      "init_budget is  1000\n",
      "3\n",
      "init_budget is  1000\n",
      "4\n",
      "init_budget is  1000\n",
      "5\n",
      "init_budget is  1000\n",
      "6\n",
      "init_budget is  1000\n",
      "7\n",
      "init_budget is  1000\n",
      "8\n",
      "init_budget is  1000\n",
      "9\n",
      "init_budget is  1000\n",
      "10\n",
      "init_budget is  1000\n",
      "11\n",
      "init_budget is  1000\n",
      "12\n",
      "init_budget is  1000\n",
      "13\n",
      "init_budget is  1000\n",
      "14\n",
      "init_budget is  1000\n",
      "15\n",
      "init_budget is  1000\n",
      "16\n",
      "init_budget is  1000\n",
      "17\n",
      "init_budget is  1000\n",
      "18\n",
      "init_budget is  1000\n",
      "19\n",
      "init_budget is  1000\n",
      "20\n",
      "init_budget is  1000\n",
      "21\n",
      "init_budget is  1000\n",
      "22\n",
      "init_budget is  1000\n",
      "23\n",
      "init_budget is  1000\n",
      "24\n",
      "init_budget is  1000\n",
      "25\n",
      "init_budget is  1000\n",
      "26\n",
      "init_budget is  1000\n",
      "27\n",
      "init_budget is  1000\n",
      "28\n",
      "init_budget is  1000\n",
      "29\n",
      "init_budget is  1000\n",
      "30\n",
      "init_budget is  1000\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 10it [00:02,  3.83it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_budget is  1000\n",
      "32\n",
      "init_budget is  1000\n",
      "33\n",
      "init_budget is  1000\n",
      "34\n",
      "init_budget is  1000\n",
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m backend \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbfs\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m bfs_yloss_cfs \u001b[39m=\u001b[39m [\n\u001b[0;32m----> 3\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39;49m\u001b[39mlstm\u001b[39;49m\u001b[39m'\u001b[39;49m], get_backend_strategy(backend), [\u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m, \u001b[39m5\u001b[39;49m, \u001b[39m7\u001b[39;49m], no_users\u001b[39m=\u001b[39;49m\u001b[39m6000\u001b[39;49m, init_budget\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m),\n\u001b[1;32m      4\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39m\u001b[39mlstm\u001b[39m\u001b[39m'\u001b[39m], get_backend_strategy(backend), [\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m7\u001b[39m], no_users\u001b[39m=\u001b[39m\u001b[39m6000\u001b[39m, init_budget\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, early_term\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m      5\u001b[0m \u001b[39m#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='loss_sim', init_budget=1000)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      8\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mstore\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbfs_yloss_cfs\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/var/folders/v1/m2nqhx3d4yv9mjbpndrlsck00000gn/T/ipykernel_41760/4207803331.py:89\u001b[0m, in \u001b[0;36m_find_cfs\u001b[0;34m(dataset, model, strategy_func, target_item_pos, no_users, init_budget, max_allowed_permutations, top_k, total_CFs, num_processes, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minit_budget is \u001b[39m\u001b[39m'\u001b[39m, init_budget)\n\u001b[1;32m     88\u001b[0m                 \u001b[39mprint\u001b[39m(user_id)\n\u001b[0;32m---> 89\u001b[0m                 best_tot_loss_data[pos]\u001b[39m.\u001b[39mextend(_retrieve_solutions((\n\u001b[1;32m     90\u001b[0m                     user_id, dataset, model, strategy_func, pos, init_budget, top_k, kwargs)))\n\u001b[1;32m     93\u001b[0m \u001b[39m#         pool = Pool(processes=min(num_processes, cpu_count() - 1, 4), initargs=(RLock(),), initializer=tqdm.set_lock)\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39m#         with Pool(processes=min(num_processes, cpu_count() - 1, 2), initializer=init, initargs=(l,)) as pool:\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[39m#         jobs = [pool.apply_async(_retrieve_solutions, args=((n,dataset,model,strategy_func,pos,init_budget,top_k,kwargs),)) \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m#                 )), total=num_users))\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39m# #                 r = list(tqdm(p.imap(_foo, range(30)), total=30))\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39mreturn\u001b[39;00m best_tot_loss_data\n",
      "File \u001b[0;32m/var/folders/v1/m2nqhx3d4yv9mjbpndrlsck00000gn/T/ipykernel_41760/4207803331.py:26\u001b[0m, in \u001b[0;36m_retrieve_solutions\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     24\u001b[0m budget \u001b[39m=\u001b[39m strategy\u001b[39m.\u001b[39mget_init_budget()\n\u001b[1;32m     25\u001b[0m \u001b[39mwhile\u001b[39;00m budget \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 26\u001b[0m     perm, curr_budget \u001b[39m=\u001b[39m strategy\u001b[39m.\u001b[39;49mnext_comb(reverse\u001b[39m=\u001b[39;49msearch_info\u001b[39m.\u001b[39;49msolution_found)\n\u001b[1;32m     28\u001b[0m     \u001b[39mif\u001b[39;00m perm \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mbreak\u001b[39;00m  \u001b[39m# there is no need to continue searching\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[39m# predict next top-k items about to be selected\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[78], line 91\u001b[0m, in \u001b[0;36mLossSimilarSelection.next_comb\u001b[0;34m(self, reverse)\u001b[0m\n\u001b[1;32m     89\u001b[0m     solved_flag, item_mask, budget \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_item()\n\u001b[1;32m     90\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mma_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mmasked_array(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_interactions, mask\u001b[39m=\u001b[39mitem_mask\u001b[39m.\u001b[39mcopy())\n\u001b[0;32m---> 91\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_queue(solved_flag)\n\u001b[1;32m     92\u001b[0m \u001b[39melse\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mma_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mmasked_array(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_interactions, mask\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     94\u001b[0m seq \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mcompressed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mma_arr)\n",
      "Cell \u001b[0;32mIn[78], line 68\u001b[0m, in \u001b[0;36mLossSimilarSelection._update_queue\u001b[0;34m(self, is_solved)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_queue\u001b[39m(\u001b[39mself\u001b[39m, is_solved):\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(is_solved)\n",
      "Cell \u001b[0;32mIn[78], line 100\u001b[0m, in \u001b[0;36mLossSimilarSelection.compute_loss\u001b[0;34m(self, is_solved)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_loss\u001b[39m(\u001b[39mself\u001b[39m, is_solved\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_comb_cost \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 100\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_solved: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msearch(forward\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, s\u001b[39m=\u001b[39;49mis_solved)\n\u001b[1;32m    101\u001b[0m     \u001b[39melse\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch(forward\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, s\u001b[39m=\u001b[39mis_solved)\n",
      "Cell \u001b[0;32mIn[78], line 109\u001b[0m, in \u001b[0;36mLossSimilarSelection.search\u001b[0;34m(self, forward, s)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m valid_items:\n\u001b[1;32m    108\u001b[0m     m_mask[idx] \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m m_mask[idx]\n\u001b[0;32m--> 109\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd(m_mask, s)\n\u001b[1;32m    110\u001b[0m     m_mask[idx] \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m m_mask[idx]\n",
      "Cell \u001b[0;32mIn[78], line 129\u001b[0m, in \u001b[0;36mLossSimilarSelection.add\u001b[0;34m(self, d, s)\u001b[0m\n\u001b[1;32m    126\u001b[0m perm \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mcompressed(np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mmasked_array(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_interactions, mask\u001b[39m=\u001b[39md))\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s:\n\u001b[0;32m--> 129\u001b[0m     t_score, kth_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_score(d)\n\u001b[1;32m    131\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq\u001b[39m.\u001b[39msize() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq\u001b[39m.\u001b[39menqueue((d\u001b[39m.\u001b[39mcopy(), t_score, \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m (t_score \u001b[39m/\u001b[39m kth_score) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m))\n\u001b[1;32m    133\u001b[0m     \u001b[39mif\u001b[39;00m t_score \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq\u001b[39m.\u001b[39mget(\u001b[39m0\u001b[39m)[\u001b[39m1\u001b[39m]:  \u001b[39m# get only the assigned score\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[78], line 117\u001b[0m, in \u001b[0;36mLossSimilarSelection.get_score\u001b[0;34m(self, d)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbudget \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    116\u001b[0m \u001b[39m# predict next top-k items about to be selected\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(perm)\n\u001b[1;32m    118\u001b[0m preds[perm] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mStaticVars\u001b[39m.\u001b[39mFLOAT_MAX\n\u001b[1;32m    119\u001b[0m rk_data \u001b[39m=\u001b[39m st\u001b[39m.\u001b[39mrankdata(\u001b[39m-\u001b[39mpreds, method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mordinal\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/CFExplainability/spotlight_ext/spotlight/sequence/implicit.py:328\u001b[0m, in \u001b[0;36mImplicitSequenceModel.predict\u001b[0;34m(self, sequences, item_ids)\u001b[0m\n\u001b[1;32m    326\u001b[0m _, sequence_representations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_net\u001b[39m.\u001b[39muser_representation(sequence_var)\n\u001b[1;32m    327\u001b[0m size \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(item_var),) \u001b[39m+\u001b[39m sequence_representations\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 328\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_net(sequence_representations\u001b[39m.\u001b[39;49mexpand(\u001b[39m*\u001b[39;49msize),\n\u001b[1;32m    329\u001b[0m                 item_var)\n\u001b[1;32m    331\u001b[0m \u001b[39mreturn\u001b[39;00m cpu(out)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/CFExplainability/spotlight_ext/spotlight/sequence/representations.py:249\u001b[0m, in \u001b[0;36mLSTMNet.forward\u001b[0;34m(self, user_representations, targets)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, user_representations, targets):\n\u001b[1;32m    230\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m    Compute predictions for target items given user representations.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39m        of shape (minibatch_size, sequence_length)\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     target_embedding \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitem_embeddings(targets)\n\u001b[1;32m    250\u001b[0m                         \u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    251\u001b[0m                         \u001b[39m.\u001b[39msqueeze())\n\u001b[1;32m    252\u001b[0m     target_bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_biases(targets)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m    254\u001b[0m     dot \u001b[39m=\u001b[39m ((user_representations \u001b[39m*\u001b[39m target_embedding)\n\u001b[1;32m    255\u001b[0m            \u001b[39m.\u001b[39msum(\u001b[39m1\u001b[39m)\n\u001b[1;32m    256\u001b[0m            \u001b[39m.\u001b[39msqueeze())\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    159\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    160\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:2199\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2193\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2194\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2195\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2196\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2197\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2198\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2199\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "backend = 'bfs'\n",
    "bfs_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, early_term=True),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='loss_sim', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store bfs_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BFS strategy with fixed ordering...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_find_cfs() missing 1 required positional argument: 'target_item_pos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mRunning BFS strategy with fixed ordering...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m bfs_fixed_yloss_cfs \u001b[39m=\u001b[39m [\n\u001b[0;32m----> 4\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39;49m\u001b[39mlstm\u001b[39;49m\u001b[39m'\u001b[39;49m], [\u001b[39m3\u001b[39;49m, \u001b[39m5\u001b[39;49m, \u001b[39m7\u001b[39;49m], no_users\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, backend\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfixed_loss_sim\u001b[39;49m\u001b[39m'\u001b[39;49m, init_budget\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m),\n\u001b[1;32m      5\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39m\u001b[39mpooling\u001b[39m\u001b[39m'\u001b[39m], [\u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m7\u001b[39m], no_users\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, backend\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfixed_loss_sim\u001b[39m\u001b[39m'\u001b[39m, init_budget\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m),\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      8\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mstore\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbfs_fixed_yloss_cfs\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: _find_cfs() missing 1 required positional argument: 'target_item_pos'"
     ]
    }
   ],
   "source": [
    "print('Running BFS strategy with fixed ordering...')\n",
    "\n",
    "bfs_fixed_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], [3, 5, 7], no_users=500, backend='fixed_loss_sim', init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='fixed_loss_sim', init_budget=1000),\n",
    "]\n",
    "\n",
    "%store bfs_fixed_yloss_cfs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilize similarities based on yloss with DFS backward search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: DFS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd08547182b4ef8ab368b27c5a5a9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 10it [00:00, 1189.74it/s]            \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 5 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m backend\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdfs_loss_sim\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m dfs_yloss_cfs \u001b[39m=\u001b[39m [\n\u001b[0;32m----> 3\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39;49m\u001b[39mlstm\u001b[39;49m\u001b[39m'\u001b[39;49m], get_backend_strategy(backend), [\u001b[39m3\u001b[39;49m, \u001b[39m5\u001b[39;49m, \u001b[39m7\u001b[39;49m], no_users\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, init_budget\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m),\n\u001b[1;32m      4\u001b[0m \u001b[39m#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='dfs_loss_sim', init_budget=1000)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      7\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mstore\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdfs_yloss_cfs\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/var/folders/v1/m2nqhx3d4yv9mjbpndrlsck00000gn/T/ipykernel_39213/2050766523.py:87\u001b[0m, in \u001b[0;36m_find_cfs\u001b[0;34m(dataset, model, strategy_func, target_item_pos, no_users, init_budget, max_allowed_permutations, top_k, total_CFs, num_processes, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m             best_tot_loss_data[pos] \u001b[39m=\u001b[39m []\n\u001b[1;32m     85\u001b[0m             \u001b[39mfor\u001b[39;00m user_id \u001b[39min\u001b[39;00m trange(\u001b[39m1\u001b[39m, num_users \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39musers loop\u001b[39m\u001b[39m'\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):  \u001b[39m# dataset.num_users):\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[39m#                 best_tot_loss_data[pos].append(_total_loss)\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m                 best_tot_loss_data[pos]\u001b[39m.\u001b[39mextend(_retrieve_solutions((\n\u001b[1;32m     88\u001b[0m                     user_id, dataset, model, strategy_func, pos, init_budget, top_k, kwargs)))\n\u001b[1;32m     91\u001b[0m \u001b[39m#         pool = Pool(processes=min(num_processes, cpu_count() - 1, 4), initargs=(RLock(),), initializer=tqdm.set_lock)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m#         with Pool(processes=min(num_processes, cpu_count() - 1, 2), initializer=init, initargs=(l,)) as pool:\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[39m#         jobs = [pool.apply_async(_retrieve_solutions, args=((n,dataset,model,strategy_func,pos,init_budget,top_k,kwargs),)) \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m#                 )), total=num_users))\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m# #                 r = list(tqdm(p.imap(_foo, range(30)), total=30))\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m best_tot_loss_data\n",
      "File \u001b[0;32m/var/folders/v1/m2nqhx3d4yv9mjbpndrlsck00000gn/T/ipykernel_39213/2050766523.py:21\u001b[0m, in \u001b[0;36m_retrieve_solutions\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     19\u001b[0m search_info \u001b[39m=\u001b[39m InteractionsInfo(user_id, target_item, items_interacted, init_budget)\n\u001b[1;32m     20\u001b[0m loss \u001b[39m=\u001b[39m ComputeLoss(target_item, items_interacted, top_k)\n\u001b[0;32m---> 21\u001b[0m strategy \u001b[39m=\u001b[39m sf(target_item, items_interacted, d\u001b[39m.\u001b[39;49mmax_sequence_length, init_budget, m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     23\u001b[0m counter \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     24\u001b[0m budget \u001b[39m=\u001b[39m strategy\u001b[39m.\u001b[39mget_init_budget()\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 5 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "backend='dfs_loss_sim'\n",
    "dfs_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='dfs_loss_sim', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store dfs_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BFS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca99755593274a57a9024608bcf9b6d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 10it [00:00, 1125.87it/s]            \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 5 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m backend\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdfs_fixed_loss_sim\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m dfs_fixed_yloss_cfs \u001b[39m=\u001b[39m [\n\u001b[0;32m----> 3\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39;49m\u001b[39mlstm\u001b[39;49m\u001b[39m'\u001b[39;49m], get_backend_strategy(backend), [\u001b[39m3\u001b[39;49m, \u001b[39m5\u001b[39;49m, \u001b[39m7\u001b[39;49m], no_users\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, init_budget\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m),\n\u001b[1;32m      4\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39m\u001b[39mpooling\u001b[39m\u001b[39m'\u001b[39m], get_backend_strategy(backend), [\u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m7\u001b[39m], no_users\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, init_budget\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m)\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      7\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mstore\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdfs_fixed_yloss_cfs\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/var/folders/v1/m2nqhx3d4yv9mjbpndrlsck00000gn/T/ipykernel_39213/2050766523.py:87\u001b[0m, in \u001b[0;36m_find_cfs\u001b[0;34m(dataset, model, strategy_func, target_item_pos, no_users, init_budget, max_allowed_permutations, top_k, total_CFs, num_processes, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m             best_tot_loss_data[pos] \u001b[39m=\u001b[39m []\n\u001b[1;32m     85\u001b[0m             \u001b[39mfor\u001b[39;00m user_id \u001b[39min\u001b[39;00m trange(\u001b[39m1\u001b[39m, num_users \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39musers loop\u001b[39m\u001b[39m'\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):  \u001b[39m# dataset.num_users):\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[39m#                 best_tot_loss_data[pos].append(_total_loss)\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m                 best_tot_loss_data[pos]\u001b[39m.\u001b[39mextend(_retrieve_solutions((\n\u001b[1;32m     88\u001b[0m                     user_id, dataset, model, strategy_func, pos, init_budget, top_k, kwargs)))\n\u001b[1;32m     91\u001b[0m \u001b[39m#         pool = Pool(processes=min(num_processes, cpu_count() - 1, 4), initargs=(RLock(),), initializer=tqdm.set_lock)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m#         with Pool(processes=min(num_processes, cpu_count() - 1, 2), initializer=init, initargs=(l,)) as pool:\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[39m#         jobs = [pool.apply_async(_retrieve_solutions, args=((n,dataset,model,strategy_func,pos,init_budget,top_k,kwargs),)) \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m#                 )), total=num_users))\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m# #                 r = list(tqdm(p.imap(_foo, range(30)), total=30))\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m best_tot_loss_data\n",
      "File \u001b[0;32m/var/folders/v1/m2nqhx3d4yv9mjbpndrlsck00000gn/T/ipykernel_39213/2050766523.py:21\u001b[0m, in \u001b[0;36m_retrieve_solutions\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     19\u001b[0m search_info \u001b[39m=\u001b[39m InteractionsInfo(user_id, target_item, items_interacted, init_budget)\n\u001b[1;32m     20\u001b[0m loss \u001b[39m=\u001b[39m ComputeLoss(target_item, items_interacted, top_k)\n\u001b[0;32m---> 21\u001b[0m strategy \u001b[39m=\u001b[39m sf(target_item, items_interacted, d\u001b[39m.\u001b[39;49mmax_sequence_length, init_budget, m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     23\u001b[0m counter \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     24\u001b[0m budget \u001b[39m=\u001b[39m strategy\u001b[39m.\u001b[39mget_init_budget()\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 5 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "backend='dfs_fixed_loss_sim'\n",
    "dfs_fixed_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['pooling'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000)\n",
    "]\n",
    "\n",
    "%store dfs_fixed_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "backend='bestFS_loss'\n",
    "bestfs_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='bestFS_loss', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store bestfs_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print('Running BestFS strategy with fixed ordering...')\n",
    "\n",
    "bestfs_fixed_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], [3, 5, 7], no_users=500, backend='bestFS_fixed_loss', init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='bestFS_fixed_loss', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store bestfs_fixed_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "backend='topdown_loss'\n",
    "topdown_bestfs_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='topdown_loss', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store topdown_bestfs_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BiDirectional\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [1:44:19, 312.97s/it]           "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [3:28:41, 443.47s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f942fb4df897464b99d03a1d27a9c69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "target position loop: 40it [7:00:22, 630.56s/it]\n",
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BiDirectional\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [1:46:46, 320.32s/it]           "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [3:33:05, 452.67s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97590ebcd26646d2b3921216131ceed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "target position loop: 40it [7:11:45, 647.64s/it]\n",
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BiDirectional\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "target position loop: 20it [1:20:25, 241.30s/it]           "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [2:39:30, 338.44s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [3:58:44, 389.55s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [5:18:24, 477.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'bidirectional_cfs' (list)\n"
     ]
    }
   ],
   "source": [
    "backend='bidirectional'\n",
    "bidirectional_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, alpha=1e-3, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, alpha=0.5, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, alpha=0.999, normalization='default'),\n",
    "]\n",
    "\n",
    "%store bidirectional_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BruteForce\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [2:59:30, 538.52s/it]           "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [4:11:08, 505.90s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [4:28:50, 385.98s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [4:33:42, 410.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'brute_force_cfs' (list)\n"
     ]
    }
   ],
   "source": [
    "backend='brute_force'\n",
    "brute_force_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=100000),\n",
    "]\n",
    "\n",
    "%store brute_force_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: Combo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [2:34:47, 464.38s/it]           "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "target position loop: 30it [4:57:44, 628.26s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [7:22:14, 717.36s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [9:48:58, 883.47s/it]\n",
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: Combo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46641deafb164ee6a03b42a96aa9043f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "target position loop: 30it [4:53:52, 623.89s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1732bb87c9439ab309944eba8113a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "target position loop: 40it [9:47:29, 881.24s/it]\n",
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: Combo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "target position loop: 20it [1:46:07, 318.37s/it]           "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [3:32:31, 451.70s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "target position loop: 40it [5:18:15, 519.91s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [7:05:47, 638.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'combo_cfs' (list)\n"
     ]
    }
   ],
   "source": [
    "backend='combo'\n",
    "combo_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, alpha=1e-3, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, alpha=0.5, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, alpha=0.999, normalization='default'),\n",
    "]\n",
    "\n",
    "%store combo_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
